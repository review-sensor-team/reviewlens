import json
from pathlib import Path
from collections import Counter

review_dir = Path('backend/data/review')
json_files = list(review_dir.glob('reviews_*.json'))

print(f'ì´ {len(json_files)}ê°œì˜ JSON íŒŒì¼ ë°œê²¬\n')

for json_file in sorted(json_files):
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # reviews í•„ë“œ ì¶”ì¶œ
        if isinstance(data, dict) and 'reviews' in data:
            reviews = data['reviews']
        elif isinstance(data, list):
            reviews = data
        else:
            print(f'âš ï¸  {json_file.name}: ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹')
            continue
        
        # ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ
        review_texts = []
        for review in reviews:
            if isinstance(review, dict):
                text = (review.get('review_text') or 
                       review.get('text') or 
                       review.get('content') or 
                       review.get('review_content') or '')
                review_texts.append(text.strip())
        
        # ì¤‘ë³µ ì¹´ìš´íŠ¸
        total = len(review_texts)
        unique = len(set(review_texts))
        duplicates = total - unique
        
        print(f'ğŸ“„ {json_file.name}')
        print(f'   ì´ ë¦¬ë·°: {total}ê°œ')
        print(f'   ê³ ìœ  ë¦¬ë·°: {unique}ê°œ')
        print(f'   ì¤‘ë³µ: {duplicates}ê°œ')
        
        # ì¤‘ë³µëœ ë¦¬ë·° ìƒì„¸ ì •ë³´
        if duplicates > 0:
            counter = Counter(review_texts)
            dup_reviews = [(text[:50], count) for text, count in counter.items() if count > 1]
            if dup_reviews:
                print(f'   ì¤‘ë³µëœ ë¦¬ë·° ì˜ˆì‹œ:')
                for text, count in sorted(dup_reviews, key=lambda x: x[1], reverse=True)[:3]:
                    print(f'      - "{text}..." ({count}ë²ˆ ë°˜ë³µ)')
        print()
        
    except Exception as e:
        print(f'âŒ {json_file.name}: ì˜¤ë¥˜ - {e}\n')
