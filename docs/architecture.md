# ReviewLens ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

ReviewLensëŠ” ì œí’ˆ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ë§¤ í›„íšŒ ìš”ì¸ì„ ì°¾ì•„ë‚´ëŠ” ëŒ€í™”í˜• AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ëª©ì°¨

- [ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì „ì²´-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
- [ë°ì´í„° ìˆ˜ì§‘ ê³„ì¸µ](#ë°ì´í„°-ìˆ˜ì§‘-ê³„ì¸µ)
- [ë¶„ì„ íŒŒì´í”„ë¼ì¸](#ë¶„ì„-íŒŒì´í”„ë¼ì¸)
- [ëŒ€í™” ì—”ì§„](#ëŒ€í™”-ì—”ì§„)
- [LLM í†µí•©](#llm-í†µí•©)
- [ëª¨ë‹ˆí„°ë§ ê³„ì¸µ](#ëª¨ë‹ˆí„°ë§-ê³„ì¸µ)
- [ë°°í¬ ì•„í‚¤í…ì²˜](#ë°°í¬-ì•„í‚¤í…ì²˜)

---

## ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "1ï¸âƒ£ ë°ì´í„° ìˆ˜ì§‘ ê³„ì¸µ"
        A1[ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´<br/>í¬ë¡¤ëŸ¬]
        A2[ë¦¬ë·° ë°ì´í„°<br/>JSON/CSV]
        A3[Factor ë¶„ì„ê¸°<br/>í›„íšŒ ìš”ì¸ ì¶”ì¶œ]
        A4[Question ìƒì„±ê¸°<br/>ëŒ€í™” ì§ˆë¬¸ ìƒì„±]
        
        A1 -->|í¬ë¡¤ë§| A2
        A2 -->|ë¶„ì„| A3
        A3 -->|ìƒì„±| A4
    end
    
    subgraph "2ï¸âƒ£ ë°ì´í„° ì €ì¥ì†Œ"
        B1[(reviews.csv<br/>ë¦¬ë·° ì›ë³¸)]
        B2[(factors.csv<br/>í›„íšŒ ìš”ì¸)]
        B3[(questions.csv<br/>ëŒ€í™” ì§ˆë¬¸)]
        
        A2 --> B1
        A3 --> B2
        A4 --> B3
    end
    
    subgraph "3ï¸âƒ£ ë°±ì—”ë“œ API Layer"
        C1[FastAPI Server<br/>:8000]
        C2[Metrics Middleware<br/>ì„±ëŠ¥ ì¸¡ì •]
        C3[CORS Middleware<br/>ë³´ì•ˆ]
        
        C2 -.-> C1
        C3 -.-> C1
    end
    
    subgraph "4ï¸âƒ£ ëŒ€í™” ì—”ì§„ Core"
        D1[Session Manager<br/>ì„¸ì…˜ ê´€ë¦¬]
        D2[Dialogue Engine<br/>ëŒ€í™” ìˆ˜ë ´ ë¡œì§]
        D3[Factor Scoring<br/>ì ìˆ˜ ê³„ì‚°]
        D4[Evidence Retrieval<br/>ì¦ê±° ë¦¬ë·° ê²€ìƒ‰]
        
        D1 --> D2
        D2 --> D3
        D3 --> D4
    end
    
    subgraph "5ï¸âƒ£ LLM í†µí•© Layer"
        E1{LLM Factory}
        E2[Gemini Client]
        E3[OpenAI Client]
        E4[Claude Client]
        E5[Fallback Handler]
        
        E1 --> E2
        E1 --> E3
        E1 --> E4
        E1 --> E5
    end
    
    subgraph "6ï¸âƒ£ í”„ë¡ íŠ¸ì—”ë“œ"
        F1[Vue.js App<br/>:3000]
        F2[ChatBot Component]
        F3[Analytics Display]
        
        F1 --> F2
        F1 --> F3
    end
    
    subgraph "7ï¸âƒ£ ëª¨ë‹ˆí„°ë§ Stack"
        G1[Prometheus<br/>:9090<br/>ë©”íŠ¸ë¦­ ìˆ˜ì§‘]
        G2[Grafana<br/>:3001<br/>ì‹œê°í™”]
        G3[Metrics Registry<br/>Counter/Histogram/Gauge]
        
        G3 -->|scrape| G1
        G1 -->|query| G2
    end
    
    %% ë°ì´í„° í”Œë¡œìš°
    B1 & B2 & B3 --> D1
    D4 --> E1
    E2 & E3 & E4 & E5 --> D2
    
    %% API í†µì‹ 
    F2 -->|HTTP POST| C1
    C1 --> D1
    D2 -->|ì‘ë‹µ| C1
    C1 -->|JSON| F2
    
    %% ëª¨ë‹ˆí„°ë§
    C2 -->|ë©”íŠ¸ë¦­| G3
    D2 -->|ë©”íŠ¸ë¦­| G3
    E1 -->|ë©”íŠ¸ë¦­| G3
    
    style A3 fill:#e1f5dd
    style D2 fill:#fff4e6
    style E1 fill:#e3f2fd
    style G1 fill:#fce4ec
```

---

## ë°ì´í„° ìˆ˜ì§‘ ê³„ì¸µ

### 1. ë¦¬ë·° í¬ë¡¤ë§ ë° ìˆ˜ì§‘

```mermaid
sequenceDiagram
    participant User
    participant Script as collect_smartstore_reviews.py
    participant Browser as Selenium WebDriver
    participant Web as Smartstore ì›¹í˜ì´ì§€
    participant File as review.json
    participant Analyzer as analyze_product_reviews.py
    participant FactorCSV as factors.csv
    participant QuestionGen as Question Generator
    participant QuestionCSV as questions.csv
    
    User->>Script: python collect_smartstore_reviews.py
    Script->>Browser: Chrome WebDriver ì´ˆê¸°í™”
    Browser->>Web: í˜ì´ì§€ ë¡œë“œ (URL)
    Web-->>Browser: HTML ë Œë”ë§
    Browser->>Browser: ë¦¬ë·° ìš”ì†Œ ì°¾ê¸° (XPath/CSS)
    Browser->>Web: ìŠ¤í¬ë¡¤/í´ë¦­ (ë‹¤ìŒ í˜ì´ì§€)
    Web-->>Browser: ì¶”ê°€ ë¦¬ë·° ë¡œë“œ
    Browser-->>Script: íŒŒì‹±ëœ ë¦¬ë·° ë°ì´í„°
    Script->>File: ì €ì¥ (í˜ì´ì§€ë„¤ì´ì…˜)
    Script-->>User: âœ… ìˆ˜ì§‘ ì™„ë£Œ
    
    User->>Analyzer: python analyze_product_reviews.py
    Analyzer->>File: ë¦¬ë·° ë¡œë“œ
    Analyzer->>Analyzer: TF-IDF ë¶„ì„<br/>í‚¤ì›Œë“œ ì¶”ì¶œ<br/>í›„íšŒ ìš”ì¸ ì‹ë³„
    Analyzer->>FactorCSV: Factor ì €ì¥<br/>(anchor/context/negation terms)
    Analyzer-->>User: âœ… ë¶„ì„ ì™„ë£Œ
    
    User->>QuestionGen: python update_dialogue.py
    QuestionGen->>FactorCSV: Factor ë¡œë“œ
    QuestionGen->>QuestionGen: ê° Factorë³„<br/>ì§ˆë¬¸ ìƒì„±<br/>(ìš°ì„ ìˆœìœ„ ì„¤ì •)
    QuestionGen->>QuestionCSV: Question ì €ì¥<br/>(factor_id ë§¤í•‘)
    QuestionGen-->>User: âœ… ì§ˆë¬¸ ìƒì„± ì™„ë£Œ
```

**ì£¼ìš” ì»´í¬ë„ŒíŠ¸**:

- **`scripts/collect_smartstore_reviews.py`**
  - ì—­í• : ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì›¹ ìŠ¤í¬ë˜í•‘ (Selenium Chrome WebDriver)
  - ê¸°ëŠ¥: ë™ì  í˜ì´ì§€ ë¡œë”©, ìŠ¤í¬ë¡¤/í´ë¦­ ìë™í™”, í˜ì´ì§€ë„¤ì´ì…˜, ì—ëŸ¬ ì²˜ë¦¬, JSON/CSV ì €ì¥
  - ê¸°ìˆ : Selenium WebDriver, undetected-chromedriver (ì„ íƒì ), XPath/CSS ì„ íƒì
  - ì¶œë ¥: `data/review/reviews_<product>_<timestamp>.json` ë˜ëŠ” `.csv`

- **`scripts/analyze_product_reviews.py`**
  - ì—­í• : ë¦¬ë·° í…ìŠ¤íŠ¸ ë¶„ì„ ë° í›„íšŒ ìš”ì¸ ì¶”ì¶œ
  - ê¸°ìˆ : TF-IDF, í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
  - ì¶œë ¥: `data/factor/reg_factor.csv`

- **Factor êµ¬ì¡°**:
  ```csv
  factor_id,category,factor_key,display_name,weight,anchor_terms,context_terms,negation_terms
  1,robot_cleaner,noise,ì†ŒìŒ,1.5,"ì†ŒìŒ|ì‹œë„ëŸ¬|ë– ë“¤","ì¡°ìš©|ì •ìˆ™","ì¡°ìš©í•˜|ê´œì°®"
  ```
  - `factor_id`: ê³ ìœ  ì‹ë³„ì
  - `category`: ì œí’ˆ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: robot_cleaner)
  - `factor_key`: Factor í‚¤ (ë‚´ë¶€ ì°¸ì¡°ìš©)
  - `display_name`: í™”ë©´ í‘œì‹œ ì´ë¦„
  - `weight`: ê°€ì¤‘ì¹˜ (ì ìˆ˜ ê³„ì‚° ì‹œ ê³±ì…ˆ)
  - `anchor_terms`: í•µì‹¬ í‚¤ì›Œë“œ (+1.0ì )
  - `context_terms`: ì—°ê´€ í‚¤ì›Œë“œ (+0.3ì )
  - `negation_terms`: ë¶€ì •/ê¸ì • ë°˜ì „ í‘œí˜„ (ì ìˆ˜ ë°˜ì˜ X, `has_neg` í”Œë˜ê·¸ë§Œ ì„¤ì •í•˜ì—¬ NEG/MIX/POS ì¦ê±° ë¶„ë¥˜ì— í™œìš©)

- **Question êµ¬ì¡°**:
  ```csv
  question_id,factor_id,factor_key,question_text,answer_type,choices,next_factor_hint
  1001,1,water_control,ë¬¼ ì–‘ì„ ì§ì ‘ ì¡°ì ˆí•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?,no_choice,,
  1002,1,water_control,ì»¤í”¼ ì‹œ ë¬¼ ê´€ë¦¬ê°€ ì¤‘ìš”í•œê°€ìš”?,single_choice,ë§¤ìš° ì¤‘ìš”|ë³´í†µ|ìƒê´€ì—†ìŒ,
  ```
  - `question_id`: ì§ˆë¬¸ ê³ ìœ  ì‹ë³„ì
  - `factor_id`: ì—°ê²°ëœ í›„íšŒ ìš”ì¸ ID (factors.csvì˜ factor_idì™€ ë§¤í•‘)
  - `factor_key`: í›„íšŒ ìš”ì¸ í‚¤ (factors.csvì˜ factor_keyì™€ ë§¤í•‘)
  - `question_text`: ì‚¬ìš©ìì—ê²Œ í‘œì‹œë˜ëŠ” ì§ˆë¬¸ í…ìŠ¤íŠ¸
  - `answer_type`: ë‹µë³€ ìœ í˜• (`no_choice`, `single_choice`, `multi_choice` ë“±)
  - `choices`: ì„ íƒì§€ ëª©ë¡ (íŒŒì´í”„ êµ¬ë¶„ì `|`, no_choiceì¸ ê²½ìš° ë¹ˆ ê°’)
  - `next_factor_hint`: ë‹¤ìŒ ì§ˆë¬¸ ì„ íƒ íŒíŠ¸ (ì„ íƒì )

### 2. ì§ˆë¬¸ ìƒì„±

```mermaid
graph LR
    A[Factor CSV] --> B[Question Generator]
    B --> C{ì§ˆë¬¸ ìœ í˜•}
    C -->|ìš°ì„ ìˆœìœ„ ë†’ìŒ| D[í•µì‹¬ ì§ˆë¬¸]
    C -->|ìš°ì„ ìˆœìœ„ ì¤‘ê°„| E[í™•ì¸ ì§ˆë¬¸]
    C -->|ìš°ì„ ìˆœìœ„ ë‚®ìŒ| F[ë³´ì¡° ì§ˆë¬¸]
    
    D & E & F --> G[questions.csv]
    
    style D fill:#ffcdd2
    style E fill:#fff9c4
    style G fill:#c8e6c9
```

**Question êµ¬ì¡°**:
```csv
question_id,factor_id,factor_key,question_text,answer_type,choices,next_factor_hint
1001,1,water_control,ë¬¼ ì–‘ì„ ì§ì ‘ ì¡°ì ˆí•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?,no_choice,,
1002,1,water_control,ì»¤í”¼ ì‹œ ë¬¼ ê´€ë¦¬ê°€ ì¤‘ìš”í•œê°€ìš”?,single_choice,ë§¤ìš° ì¤‘ìš”|ë³´í†µ|ìƒê´€ì—†ìŒ,
```
- `question_id`: ì§ˆë¬¸ ê³ ìœ  ì‹ë³„ì
- `factor_id`: ì—°ê²°ëœ í›„íšŒ ìš”ì¸ ID (factors.csvì˜ factor_idì™€ ë§¤í•‘)
- `factor_key`: í›„íšŒ ìš”ì¸ í‚¤ (factors.csvì˜ factor_keyì™€ ë§¤í•‘)
- `question_text`: ì‚¬ìš©ìì—ê²Œ í‘œì‹œë˜ëŠ” ì§ˆë¬¸ í…ìŠ¤íŠ¸
- `answer_type`: ë‹µë³€ ìœ í˜• (`no_choice`, `single_choice`, `multi_choice` ë“±)
- `choices`: ì„ íƒì§€ ëª©ë¡ (íŒŒì´í”„ êµ¬ë¶„ì `|`, no_choiceì¸ ê²½ìš° ë¹ˆ ê°’)
- `next_factor_hint`: ë‹¤ìŒ ì§ˆë¬¸ ì„ íƒ íŒíŠ¸ (ì„ íƒì )

---

## ë¶„ì„ íŒŒì´í”„ë¼ì¸

### 1. ì„¸ì…˜ ì´ˆê¸°í™” ë° ë°ì´í„° ë¡œë”©

```mermaid
flowchart TD
    A[ì‚¬ìš©ì ì œí’ˆ URL ì…ë ¥] --> B[URL ê²€ì¦]
    B --> C{í•´ë‹¹ ì œí’ˆ ë¦¬ë·° ë°ì´í„°<br/>ì´ë¯¸ ì¡´ì¬?}
    
    C -->|Yes| D[ìºì‹œëœ ë¦¬ë·° ë¡œë“œ<br/>ì„¸ì…˜ ì €ì¥ì†Œ]
    C -->|No| E[í¬ë¡¤ë§ íŠ¸ë¦¬ê±°]
    
    E --> F[Selenium WebDriver ì‹¤í–‰]
    F --> G[ë¦¬ë·° ìˆ˜ì§‘ & ì„¸ì…˜ ì €ì¥]
    G --> D
    
    D --> H[DialogueSession ìƒì„±]
    H --> I[Category í•„í„°ë§]
    I --> J[Factor Map ìƒì„±]
    J --> K[ì„¸ì…˜ ì¤€ë¹„ ì™„ë£Œ]
    
    K --> L{ë©”íŠ¸ë¦­ ê¸°ë¡}
    L -->|dialogue_sessions_total| M[Prometheus]
    
    style H fill:#e1f5dd
    style L fill:#fce4ec
```

**ì£¼ìš” ë¡œì§** (`backend/pipeline/dialogue.py`):

```python
class DialogueSession:
    def __init__(self, category, data_dir, reviews_df=None):
        # 1. ë°ì´í„° ë¡œë“œ
        # - reviews_df: ì„¸ì…˜ ì €ì¥ì†Œì—ì„œ ì „ë‹¬ë°›ì€ ë¦¬ë·° (ìš´ì˜)
        # - None: CSVì—ì„œ ë¡œë“œ (í…ŒìŠ¤íŠ¸/ê°œë°œ)
        self.reviews_df = reviews_df
        
        # 2. Factor/Question íŒŒì‹±
        all_factors = parse_factors(factors_df)
        self.factors = [f for f in all_factors if f.category == category]
        self.questions = parse_questions(questions_df)
        
        # 3. ë©”íŠ¸ë¦­ ê¸°ë¡
        dialogue_sessions_total.labels(category=category).inc()
```

### 2. ëŒ€í™” í„´ ì²˜ë¦¬ (Factor Convergence)

```mermaid
stateDiagram-v2
    [*] --> ReceiveMessage: ì‚¬ìš©ì ë©”ì‹œì§€
    
    ReceiveMessage --> NormalizeText: í…ìŠ¤íŠ¸ ì •ê·œí™”
    NormalizeText --> MatchFactors: Factor ë§¤ì¹­
    
    MatchFactors --> ScoreCalculation: ì ìˆ˜ ê³„ì‚°
    ScoreCalculation --> Top3Extraction: Top 3 ì¶”ì¶œ
    
    Top3Extraction --> ConvergenceCheck: ìˆ˜ë ´ ì²´í¬
    ConvergenceCheck --> Converged: Jaccard > 0.7
    ConvergenceCheck --> NotConverged: Jaccard â‰¤ 0.7
    
    Converged --> Finalize: ìµœì¢… ë¶„ì„
    NotConverged --> NextQuestion: ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
    
    NextQuestion --> [*]: BotTurn ë°˜í™˜
    Finalize --> EvidenceRetrieval: ì¦ê±° ìˆ˜ì§‘
    EvidenceRetrieval --> LLMSummary: LLM ìš”ì•½
    LLMSummary --> [*]: ì™„ë£Œ
    
    note right of MatchFactors
        anchor_terms: 1.0ì 
        context_terms: 0.3ì 
        weight ê³±ì…ˆ
    end note
    
    note right of ConvergenceCheck
        prev_top3 vs cur_top3
        Jaccard similarity
        3íšŒ ì—°ì† ì•ˆì • ì‹œ ìˆ˜ë ´
    end note
```

**í•µì‹¬ ì•Œê³ ë¦¬ì¦˜**:

```python
def step(self, user_message: str) -> BotTurn:
    # 1. ì •ê·œí™” ë° ë§¤ì¹­
    norm = normalize(user_message)
    for factor in self.factors:
        score = 0
        if any(t in norm for t in factor.anchor_terms):
            score += 1.0
        if any(t in norm for t in factor.context_terms):
            score += 0.3
        
        weighted_score = score * factor.weight
        self.cumulative_scores[factor.factor_key] += weighted_score
    
    # 2. Top 3 ì¶”ì¶œ
    top_factors = self._get_top_factors(top_k=3)
    
    # 3. ìˆ˜ë ´ ì²´í¬ (Jaccard similarity)
    jaccard = _jaccard(self.prev_top3, cur_top3)
    if jaccard > 0.7:
        self.stability_hits += 1
    
    # 4. ìˆ˜ë ´ ì¡°ê±´: 3íšŒ ì—°ì† ì•ˆì • OR 5í„´ ê²½ê³¼
    if self.stability_hits >= 3 or self.turn_count >= 5:
        return self._finalize(top_factors)
```

### 3. Evidence Retrieval (ì¦ê±° ë¦¬ë·° ê²€ìƒ‰)

```mermaid
graph TB
    A[Top Factors] --> B[Review Scoring]
    B --> C[Label Assignment<br/>NEG/MIX/POS]
    C --> D{Quota System}
    
    D -->|Rank 0<br/>Top 1| E[NEG:3, MIX:2, POS:1]
    D -->|Rank 1<br/>Top 2| F[NEG:2, MIX:2, POS:1]
    D -->|Rank 2<br/>Top 3| G[NEG:2, MIX:2, POS:1]
    
    E & F & G --> H[Evidence Pool]
    H --> I[Max 15ê°œ ì œí•œ]
    I --> J[ìµœì¢… Evidence]
    
    style C fill:#fff9c4
    style I fill:#ffcdd2
```

**Label ë¶„ë¥˜ ë¡œì§** (`backend/pipeline/retrieval.py`):

```python
def _assign_label(row, factor_key):
    score = row.get(f"score_{factor_key}", 0)
    rating = row.get("rating", 5)
    
    # 1. ì ìˆ˜ ê¸°ë°˜
    if score >= 2.0 and rating <= 3:
        return "NEG"  # ê°•í•œ ë¶€ì •
    elif score >= 1.0 and rating == 4:
        return "MIX"  # í˜¼ì¬
    elif score >= 1.0 and rating == 5:
        return "POS"  # ê¸ì •
    else:
        return None  # í•„í„°ë§
```

### 4. Scoring Pipeline

```mermaid
flowchart TD
    A[ë¦¬ë·° DataFrame] --> B[compute_review_factor_scores]
    
    B --> C[ê° ë¦¬ë·° ìˆœíšŒ]
    C --> D{Factor ë§¤ì¹­}
    
    D -->|anchor match| E[base_score += 1.0]
    D -->|context match| F[base_score += 0.3]
    D -->|negation match| G["has_neg í”Œë˜ê·¸ ì„¤ì • (ê°ì  X)"]
    
    E & F --> H[factor.weight ê³±ì…ˆ]
    H --> I["rating multiplier: 1.0 + (5-rating)*0.2"]
    I --> J[final_score]
    
    J --> K["scored_dfì— ì¶”ê°€ (score_factor_key ì»¬ëŸ¼)"]
    G --> L["has_neg_factor_key ì»¬ëŸ¼ ì¶”ê°€"]
    
    style H fill:#e1f5dd
    style I fill:#fff4e6
    style K fill:#e3f2fd
    style L fill:#ffe0b2
```

**ë©”íŠ¸ë¦­ ê³„ì¸¡**:
```python
with Timer(scoring_duration_seconds, {'category': self.category}):
    self.scored_df, self.factor_counts = compute_review_factor_scores(
        self.reviews_df, 
        self.factors
    )
```

---

## ëŒ€í™” ì—”ì§„

### DialogueSession State Machine

```mermaid
stateDiagram-v2
    [*] --> Initialized: __init__()
    
    Initialized --> Turn1: step(user_msg)
    Turn1 --> Turn2: question
    Turn2 --> Turn3: question
    Turn3 --> CheckConvergence
    
    CheckConvergence --> Turn4: not converged
    CheckConvergence --> Finalized: converged
    Turn4 --> Turn5
    Turn5 --> Finalized: max turns
    
    Finalized --> RetrievalStage: retrieve_evidence
    RetrievalStage --> ScoringStage: compute_scores
    ScoringStage --> LLMStage: generate_summary
    LLMStage --> [*]: BotTurn(is_final=True)
    
    note right of CheckConvergence
        Jaccard(prev_top3, cur_top3) > 0.7
        stability_hits >= 3
    end note
    
    note right of Finalized
        max_turns: 5
        min_turns: 3
    end note
```

**ì„¸ì…˜ ë°ì´í„° êµ¬ì¡°**:

```python
@dataclass
class BotTurn:
    question_text: Optional[str]        # ë‹¤ìŒ ì§ˆë¬¸
    top_factors: List[Tuple[str, float]]  # (factor_key, score)
    is_final: bool                       # ì™„ë£Œ ì—¬ë¶€
    llm_context: Optional[Dict]          # LLM ì‘ë‹µ
    question_id: Optional[str]           # ì§ˆë¬¸ ID
    answer_type: Optional[str]           # no_choice | single_choice
    choices: Optional[str]               # ì„ íƒì§€
```

---

## LLM í†µí•©

### LLM Factory Pattern

```mermaid
classDiagram
    class BaseLLMClient {
        <<abstract>>
        +generate_summary()
    }
    
    class GeminiClient {
        -api_key: str
        -model: str
        +generate_summary()
        -_build_prompt()
        -_get_fallback_summary()
    }
    
    class OpenAIClient {
        -api_key: str
        -model: str
        +generate_summary()
        -_build_prompts()
        -_get_fallback_summary()
    }
    
    class ClaudeClient {
        -api_key: str
        -model: str
        +generate_summary()
        -_build_prompts()
        -_get_fallback_summary()
    }
    
    class LLMFactory {
        +create_client()
    }
    
    class Settings {
        +LLM_PROVIDER: str
        +GEMINI_API_KEY: str
        +OPENAI_API_KEY: str
        +CLAUDE_MODEL: str
    }
    
    BaseLLMClient <|-- GeminiClient
    BaseLLMClient <|-- OpenAIClient
    BaseLLMClient <|-- ClaudeClient
    LLMFactory ..> BaseLLMClient : creates
    LLMFactory ..> Settings : reads
    
    note for BaseLLMClient "ëª¨ë“  LLM í´ë¼ì´ì–¸íŠ¸ì˜ ê³µí†µ ì¸í„°í˜ì´ìŠ¤"
    note for LLMFactory "í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ë™ì  í´ë¼ì´ì–¸íŠ¸ ìƒì„±"
```

### LLM í˜¸ì¶œ í”Œë¡œìš°

```mermaid
sequenceDiagram
    participant D as DialogueSession
    participant F as LLMFactory
    participant S as Settings
    participant C as LLM Client
    participant API as LLM API
    participant M as Metrics
    
    D->>D: _finalize() í˜¸ì¶œ
    D->>F: get_llm_client()
    F->>S: LLM_PROVIDER ì¡°íšŒ
    S-->>F: "openai"
    F->>F: create_client("openai")
    F-->>D: OpenAIClient
    
    D->>M: Timer ì‹œì‘
    D->>C: generate_summary(top_factors, evidence, ...)
    C->>C: _build_prompts()
    C->>API: chat.completions.create()
    
    alt API ì„±ê³µ
        API-->>C: ìš”ì•½ í…ìŠ¤íŠ¸
        C-->>D: summary
        D->>M: llm_calls_total{status='success'}
        D->>M: llm_duration_seconds
    else API ì‹¤íŒ¨
        API-->>C: Error
        C->>C: _get_fallback_summary()
        C-->>D: fallback message
        D->>M: llm_calls_total{status='error'}
        D->>M: llm_calls_total{status='fallback'}
    end
    
    D-->>D: llm_summary ë°˜í™˜
```

**í”„ë¡¬í”„íŠ¸ êµ¬ì¡°**:

```python
# System Prompt
"""ë‹¹ì‹ ì€ ì œí’ˆ ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
êµ¬ë§¤ í›„íšŒë¥¼ ì¤„ì´ê¸° ìœ„í•œ í†µì°°ì„ ì œê³µí•˜ì„¸ìš”."""

# User Prompt
f"""
ì œí’ˆ: {product_name} ({category_name})
ëŒ€í™” í„´ ìˆ˜: {total_turns}

í•µì‹¬ í›„íšŒ ìš”ì¸ Top 5:
1. {factor1} (ì ìˆ˜: {score1})
...

ì¦ê±° ë¦¬ë·° (ë¶€ì •ì ):
- "{review_text}" (í‰ì : {rating})
...

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”:
1. í•µì‹¬ í›„íšŒ ìš”ì¸ ì„¤ëª… (2-3ë¬¸ì¥)
2. êµ¬ë§¤ ì „ ì²´í¬í¬ì¸íŠ¸ (3-5ê°œ)
3. í•œ ì¤„ ì¡°ì–¸
"""
```

---

## ëª¨ë‹ˆí„°ë§ ê³„ì¸µ

> ğŸ“Š ìƒì„¸ ë¬¸ì„œ: [MONITORING_ARCHITECTURE.md](MONITORING_ARCHITECTURE.md)

### ì•„í‚¤í…ì²˜ ê°œìš”

ReviewLensëŠ” **Prometheus + Grafana** ê¸°ë°˜ ê´€ì¸¡ì„± ìŠ¤íƒì„ ì‚¬ìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥, ì‹ ë¢°ì„±, ì‚¬ìš©ì ê²½í—˜ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•©ë‹ˆë‹¤.

**í•µì‹¬ íŠ¹ì§•**:
- âœ… ìë™ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (ë¯¸ë“¤ì›¨ì–´ ê¸°ë°˜)
- âœ… ìµœì†Œ ì¹¨íˆ¬ì„± (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì˜í–¥ ì—†ìŒ)
- âœ… Dockerì™€ ë¡œì»¬ ë°”ì´ë„ˆë¦¬ ëª¨ë‘ ì§€ì›
- âœ… ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ (10-15ì´ˆ ê°„ê²©)
- âœ… ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ Registry ì‚¬ìš©

### Metrics ìˆ˜ì§‘ êµ¬ì¡°

```mermaid
graph TB
    subgraph "Application Layer"
        A1[FastAPI Server<br/>:8000]
        A2[MetricsMiddleware<br/>ìë™ HTTP ì¶”ì ]
        A3[Dialogue Engine]
        A4[LLM Clients<br/>Gemini/OpenAI/Claude]
        
        A2 -.-> A1
        A1 --> A3
        A3 --> A4
    end
    
    subgraph "Metrics Registry (backend/core/metrics.py)"
        M1[HTTP Metrics<br/>Counter/Histogram]
        M2[Dialogue Metrics<br/>Counter/Gauge]
        M3[LLM Metrics<br/>Counter/Histogram]
        M4[Pipeline Metrics<br/>Histogram]
        M5[Error Metrics<br/>Counter]
        
        A2 --> M1
        A3 --> M2
        A4 --> M3
        A3 --> M4
        A1 & A3 & A4 --> M5
    end
    
    subgraph "Prometheus (:9090)"
        P1[Scraper<br/>10-15ì´ˆ ê°„ê²©]
        P2[TSDB<br/>ì‹œê³„ì—´ DB]
        P3[PromQL Engine<br/>ì¿¼ë¦¬ ì—”ì§„]
        
        M1 & M2 & M3 & M4 & M5 -->|/metrics endpoint| P1
        P1 --> P2
        P2 --> P3
    end
    
    subgraph "Grafana (:3001)"
        G1[Dashboards<br/>3ê°œ ì œê³µ]
        G2[Auto-provisioning<br/>ë°ì´í„°ì†ŒìŠ¤/ëŒ€ì‹œë³´ë“œ]
        G3[Alerting<br/>ì„ íƒì‚¬í•­]
        
        P3 -->|PromQL queries| G1
        G2 --> G1
        G1 --> G3
    end
    
    style M1 fill:#e1f5dd
    style P2 fill:#fff4e6
    style G1 fill:#e3f2fd
```

### ì£¼ìš” ë©”íŠ¸ë¦­ ì •ì˜

#### 1. HTTP ë©”íŠ¸ë¦­ (ìë™ ìˆ˜ì§‘)

**`http_requests_total`** (Counter)
```python
# ë ˆì´ë¸”: method, endpoint, status_code
# ì‚¬ìš©: ìš”ì²­ ìˆ˜, RPS, ì—ëŸ¬ìœ¨ ê³„ì‚°
http_requests_total.labels(
    method="POST",
    endpoint="/api/chat/message",
    status_code="200"
).inc()
```

**`http_request_duration_seconds`** (Histogram)
```python
# ë ˆì´ë¸”: method, endpoint
# Buckets: 0.01s ~ 10.0s (8ë‹¨ê³„)
# ì‚¬ìš©: p50/p95/p99 latency ê³„ì‚°
http_request_duration_seconds.labels(
    method="POST",
    endpoint="/api/chat/message"
).observe(0.234)  # 234ms
```

#### 2. ëŒ€í™” ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­

```python
# ì„¸ì…˜ ìƒì„±
dialogue_sessions_total.labels(category='robot_cleaner').inc()

# ëŒ€í™” í„´
dialogue_turns_total.labels(category='robot_cleaner').inc()

# ëŒ€í™” ì™„ë£Œ
dialogue_completions_total.labels(category='robot_cleaner').inc()

# Evidence ìˆ˜ì§‘
evidence_count.labels(category='robot_cleaner').observe(15)
active_evidence_gauge.labels(
    category='robot_cleaner',
    session_id='abc123'
).set(15)
```

#### 3. LLM API ë©”íŠ¸ë¦­

```python
# API í˜¸ì¶œ
llm_calls_total.labels(
    provider='gemini',
    status='success'  # success/error/fallback
).inc()

# ì‘ë‹µ ì‹œê°„
with Timer(llm_duration_seconds, {'provider': 'gemini'}):
    response = client.generate_content(prompt)

# í† í° ì‚¬ìš©ëŸ‰
llm_tokens_total.labels(provider='gemini', type='prompt').inc(150)
llm_tokens_total.labels(provider='gemini', type='completion').inc(500)
```

#### 4. íŒŒì´í”„ë¼ì¸ ë©”íŠ¸ë¦­

```python
# Retrieval ì„±ëŠ¥
with Timer(retrieval_duration_seconds, {'category': category}):
    evidence = retrieve_evidence_reviews(...)

# Scoring ì„±ëŠ¥
with Timer(scoring_duration_seconds, {'category': category}):
    scores = calculate_factor_scores(...)
```

#### 5. ì—ëŸ¬ ì¶”ì 

```python
# ì—ëŸ¬ ë°œìƒ ì‹œ
errors_total.labels(
    error_type='llm_timeout',
    component='llm_client'
).inc()
```

### ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸

**êµ¬í˜„** ([backend/app/api/routes_metrics.py](../backend/app/api/routes_metrics.py)):
```python
@router.get("/metrics", include_in_schema=False)
async def metrics():
    """Prometheus ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸"""
    metrics_data = get_metrics()  # backend.core.metrics.get_metrics()
    return Response(
        content=metrics_data,
        media_type="text/plain; version=0.0.4; charset=utf-8"
    )
```

**ì¶œë ¥ ì˜ˆì‹œ** (http://localhost:8000/metrics):
```prometheus
# HELP http_requests_total Total HTTP requests
# TYPE http_requests_total counter
http_requests_total{endpoint="/api/chat/start",method="POST",status_code="200"} 15.0
http_requests_total{endpoint="/api/chat/message",method="POST",status_code="200"} 47.0

# HELP http_request_duration_seconds HTTP request latency in seconds
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{endpoint="/api/chat/message",method="POST",le="0.01"} 2.0
http_request_duration_seconds_bucket{endpoint="/api/chat/message",method="POST",le="0.05"} 12.0
...
```

### Prometheus ì„¤ì •

**ë¡œì»¬ ê°œë°œ** ([monitoring/prometheus.yml](../monitoring/prometheus.yml)):
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'reviewlens-backend'
    scrape_interval: 10s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['localhost:8000']
```

**Docker í™˜ê²½** ([monitoring/prometheus/prometheus.yml](../monitoring/prometheus/prometheus.yml)):
```yaml
global:
  scrape_interval: 10s

scrape_configs:
  - job_name: 'reviewlens-api'
    static_configs:
      - targets: ['host.docker.internal:8000']  # Docker â†’ í˜¸ìŠ¤íŠ¸
```

### Grafana ëŒ€ì‹œë³´ë“œ

**ì œê³µ ëŒ€ì‹œë³´ë“œ**:
1. **reviewlens_dashboard.json** - ê¸°ë³¸ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ
   - HTTP ìš”ì²­ ì†ë„ (RPS)
   - HTTP Latency (p50/p95/p99)
   - ì—ëŸ¬ìœ¨ (4xx/5xx)
   - ëŒ€í™” ì„¸ì…˜/í„´ ì¶”ì„¸
   
2. **reviewlens-demo-kr.json** - ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤ìš©
   - ì‚¬ìš©ì ì—¬ì • ì¶”ì 
   - ì‹¤ì‹œê°„ ëŒ€í™” í”Œë¡œìš°
   
3. **reviewlens-production-kr-v2.json** - í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§
   - SLA ì¶”ì 
   - ì•Œë¦¼ ê°œìš”
   - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰

**ìë™ í”„ë¡œë¹„ì €ë‹**:
- ë°ì´í„°ì†ŒìŠ¤: Prometheus ìë™ ì—°ê²°
- ëŒ€ì‹œë³´ë“œ: ì‹œì‘ ì‹œ ìë™ ë¡œë“œ
- ì„¤ì •: [monitoring/grafana/provisioning/](../monitoring/grafana/provisioning/)

### ë°°í¬ ì˜µì…˜

| ë°©ì‹ | ëª…ë ¹ì–´ | ìš©ë„ |
|------|--------|------|
| **ë¡œì»¬ ë°”ì´ë„ˆë¦¬** | `./scripts/start_monitoring.sh` | ê°œë°œ í™˜ê²½ (ë¹ ë¥¸ ì‹œì‘) |
| **Docker Compose** | `docker-compose -f docker-compose.monitoring.yml up -d` | ìŠ¤í…Œì´ì§•/í”„ë¡œë•ì…˜ |

**íŒŒì¼ êµ¬ì¡°**:
```
monitoring/
â”œâ”€â”€ prometheus.yml              # ë¡œì»¬ìš©
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml         # Dockerìš©
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â”œâ”€â”€ datasources/
â”‚   â”‚   â”‚   â””â”€â”€ prometheus.yml # ìë™ ë°ì´í„°ì†ŒìŠ¤ ì„¤ì •
â”‚   â”‚   â””â”€â”€ dashboards/
â”‚   â”‚       â””â”€â”€ dashboard.yml  # ëŒ€ì‹œë³´ë“œ í”„ë¡œë¹„ì €ë‹
â”‚   â””â”€â”€ dashboards/
â”‚       â”œâ”€â”€ reviewlens_dashboard.json
â”‚       â”œâ”€â”€ reviewlens-demo-kr.json
â”‚       â””â”€â”€ reviewlens-production-kr-v2.json
scripts/
â”œâ”€â”€ start_monitoring.sh        # ë¡œì»¬ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ stop_monitoring.sh         # ë¡œì»¬ ì¢…ë£Œ ìŠ¤í¬ë¦½íŠ¸
```

### PromQL ì¿¼ë¦¬ ì˜ˆì‹œ

```promql
# ì´ˆë‹¹ ìš”ì²­ ìˆ˜ (RPS)
rate(http_requests_total[1m])

# p95 Latency
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# ì—ëŸ¬ìœ¨
sum(rate(http_requests_total{status_code=~"[45].."}[5m])) / 
sum(rate(http_requests_total[5m])) * 100

# ì„¸ì…˜ë‹¹ í‰ê·  í„´ ìˆ˜
sum(rate(dialogue_turns_total[1h])) / 
sum(rate(dialogue_sessions_total[1h]))

# LLM í† í° ì‚¬ìš©ëŸ‰ (ì‹œê°„ë‹¹)
rate(llm_tokens_total[1h]) * 3600

# Providerë³„ LLM p95 latency
histogram_quantile(0.95, 
  sum by (provider, le) (rate(llm_duration_seconds_bucket[5m]))
)
```

### ì„±ëŠ¥ ìµœì í™”

**ë©”íŠ¸ë¦­ ì¹´ë””ë„ë¦¬í‹° ê´€ë¦¬**:
```python
# âŒ ë‚˜ìœ ì˜ˆ: session_idë¥¼ ë ˆì´ë¸”ë¡œ ì‚¬ìš© (ë¬´í•œ ì¦ê°€)
dialogue_turns_total.labels(session_id=session_id).inc()

# âœ… ì¢‹ì€ ì˜ˆ: categoryë§Œ ë ˆì´ë¸”ë¡œ
dialogue_turns_total.labels(category=category).inc()
logger.info(f"Turn recorded for session {session_id}")
```

**Histogram Bucket ìµœì í™”**:
- HTTP ìš”ì²­: `(0.01, 0.05, 0.1, 0.5, 1.0, 2.5, 5.0, 10.0)`
- LLM API: `(0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 30.0)`

**Retention ì •ì±…**:
- ê°œë°œ: 7-15ì¼
- í”„ë¡œë•ì…˜: 30-90ì¼
- ì¥ê¸° ì €ì¥: Thanos, Cortex ë“± í™œìš©

### ì ‘ì† ì •ë³´

- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3001 (admin/admin)
- **Metrics Endpoint**: http://localhost:8000/metrics

---

## ë°°í¬ ì•„í‚¤í…ì²˜

### í™˜ê²½ë³„ ë°°í¬ ì „ëµ

```mermaid
graph TB
    subgraph "ê°œë°œ í™˜ê²½ (Local)"
        L1[ë¡œì»¬ PC]
        L2[Python FastAPI<br/>:8000]
        L3[Vue Dev Server<br/>:3000]
        L4[Prometheus Binary<br/>:9090]
        L5[Grafana Binary<br/>:3001]
        
        L1 --> L2
        L1 --> L3
        L1 --> L4
        L1 --> L5
        
        L2 -.->|ë©”íŠ¸ë¦­| L4
        L4 -.->|ì¿¼ë¦¬| L5
    end
    
    subgraph "ìŠ¤í…Œì´ì§• í™˜ê²½ (Docker)"
        S1[VM/EC2]
        S2[Docker Compose]
        S3[API Container]
        S4[Prometheus Container]
        S5[Grafana Container]
        
        S1 --> S2
        S2 --> S3
        S2 --> S4
        S2 --> S5
    end
    
    subgraph "í”„ë¡œë•ì…˜ í™˜ê²½ (Kubernetes)"
        P1[K8s Cluster]
        P2[API Deployment<br/>replicas: 3]
        P3[Prometheus Operator]
        P4[Grafana Service]
        P5[Ingress<br/>Load Balancer]
        
        P1 --> P2
        P1 --> P3
        P1 --> P4
        P1 --> P5
        P5 --> P2
    end
    
    style L1 fill:#e8f5e9
    style S1 fill:#fff3e0
    style P1 fill:#e3f2fd
```

### ë°°í¬ í”Œë¡œìš°

```mermaid
sequenceDiagram
    participant Dev as ê°œë°œì
    participant Git as GitHub
    participant CI as CI/CD
    participant Reg as Container Registry
    participant K8s as Kubernetes
    participant Mon as Monitoring
    
    Dev->>Git: git push
    Git->>CI: Webhook trigger
    
    CI->>CI: 1. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    CI->>CI: 2. Docker ì´ë¯¸ì§€ ë¹Œë“œ
    CI->>Reg: 3. ì´ë¯¸ì§€ í‘¸ì‹œ
    
    CI->>K8s: 4. kubectl apply
    K8s->>K8s: 5. Rolling Update
    K8s->>K8s: 6. Health Check
    
    K8s-->>Mon: 7. ë©”íŠ¸ë¦­ ë…¸ì¶œ
    Mon->>Mon: 8. ì•Œë¦¼ ì²´í¬
    
    alt ë°°í¬ ì„±ê³µ
        Mon-->>Dev: âœ… ë°°í¬ ì™„ë£Œ ì•Œë¦¼
    else ë°°í¬ ì‹¤íŒ¨
        K8s->>K8s: Rollback
        Mon-->>Dev: âŒ ë°°í¬ ì‹¤íŒ¨ ì•Œë¦¼
    end
```

---

## ë°ì´í„° í”Œë¡œìš° ì¢…í•©

```mermaid
flowchart TD
    subgraph "ì‚¬ì „ ì¤€ë¹„ (ì˜¤í”„ë¼ì¸)"
        P1[ìƒ˜í”Œ ì œí’ˆ ë¦¬ë·° ìˆ˜ì§‘] --> P2[ë¦¬ë·° JSON/CSV ì €ì¥]
        P2 --> P3[Factor ë¶„ì„]
        P3 --> P4[Question ìƒì„±]
        P4 --> P5[(factors.csv<br/>questions.csv)]
    end
    
    subgraph "ì‹¤ì‹œê°„ ë¶„ì„ (ì˜¨ë¼ì¸)"
        Start([ì‚¬ìš©ì ì ‘ì†]) --> A[ì œí’ˆ URL ì…ë ¥]
        A --> B[URL ê²€ì¦]
        
        B --> C[í¬ë¡¤ë§ íŠ¸ë¦¬ê±°]
        C --> D[Selenium WebDriver ì‹¤í–‰]
        D --> E[ë¦¬ë·° ìˆ˜ì§‘]
        E --> F[ì„¸ì…˜ ë©”ëª¨ë¦¬ì— ì €ì¥]
        
        F --> H[DialogueSession ìƒì„±]
        P5 -.->|ë¡œë“œ| H
        
        H --> I[ëŒ€í™” ì‹œì‘]
        I --> J[ì‚¬ìš©ì ë©”ì‹œì§€]
        J --> K[Factor ë§¤ì¹­ & ìŠ¤ì½”ì–´ë§]
        K --> L{ìˆ˜ë ´ ì²´í¬}
        
        L -->|Not Converged| M[ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±]
        M --> J
        
        L -->|Converged| N[Evidence Retrieval]
        N --> O[Top 5 Factor í™•ì •]
        O --> Q[LLM ìš”ì•½ ìƒì„±]
        
        Q --> R{LLM ì„±ê³µ?}
        R -->|Yes| S[í’ë¶€í•œ ìš”ì•½]
        R -->|No| T[Fallback ë©”ì‹œì§€]
        
        S --> U[ìµœì¢… ê²°ê³¼ í‘œì‹œ]
        T --> U
        U --> End([ëŒ€í™” ì¢…ë£Œ])
    end
    
    %% ëª¨ë‹ˆí„°ë§
    J -.->|ë©”íŠ¸ë¦­| Mon[Prometheus]
    K -.->|ë©”íŠ¸ë¦­| Mon
    N -.->|ë©”íŠ¸ë¦­| Mon
    Q -.->|ë©”íŠ¸ë¦­| Mon
    Mon -.-> Dash[Grafana Dashboard]
    
    style P3 fill:#ffe0b2
    style F fill:#fff9c4
    style Q fill:#c5cae9
    style Mon fill:#f8bbd0
    style End fill:#c8e6c9
```

---

## ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ìƒì„¸

### 1. ë°±ì—”ë“œ API (`backend/app/`)

| íŒŒì¼ | ì—­í•  | í•µì‹¬ ê¸°ëŠ¥ |
|------|------|----------|
| `main.py` | FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ©í† ë¦¬ | ë¯¸ë“¤ì›¨ì–´ ë“±ë¡, ë¼ìš°í„° ì„¤ì •, .env ë¡œë”© |
| `api/routes_chat.py` | ëŒ€í™” API ì—”ë“œí¬ì¸íŠ¸ | `/start`, `/message` ì²˜ë¦¬ |
| `api/routes_metrics.py` | ë©”íŠ¸ë¦­ ë…¸ì¶œ | `/metrics` Prometheus í˜•ì‹ |

### 2. íŒŒì´í”„ë¼ì¸ (`backend/pipeline/`)

| íŒŒì¼ | ì—­í•  | í•µì‹¬ ê¸°ëŠ¥ |
|------|------|----------|
| `dialogue.py` | ëŒ€í™” ì—”ì§„ | ìˆ˜ë ´ ë¡œì§, ì§ˆë¬¸ ìƒì„±, ìµœì¢… ë¶„ì„ |
| `sensor.py` | Factor ìŠ¤ì½”ì–´ë§ | TF ë§¤ì¹­, weight ê³±ì…ˆ, rating multiplier |
| `retrieval.py` | Evidence ê²€ìƒ‰ | Label ë¶„ë¥˜ (NEG/MIX/POS), Quota ì ìš© |
| `reg_store.py` | ë°ì´í„° ë¡œë”© | CSV íŒŒì‹±, Factor ê°ì²´ ìƒì„± |
| `ingest.py` | í…ìŠ¤íŠ¸ ì •ê·œí™” | ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜ |

### 3. LLM í†µí•© (`backend/services/`)

| íŒŒì¼ | ì—­í•  | Provider |
|------|------|----------|
| `llm_base.py` | ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤ | - |
| `llm_gemini.py` | Google Gemini í´ë¼ì´ì–¸íŠ¸ | `gemini-1.5-flash` |
| `llm_openai.py` | OpenAI í´ë¼ì´ì–¸íŠ¸ | `gpt-4o-mini` |
| `llm_claude.py` | Anthropic Claude í´ë¼ì´ì–¸íŠ¸ | `claude-3-5-sonnet` |
| `llm_factory.py` | Factory íŒ¨í„´ | ë™ì  í´ë¼ì´ì–¸íŠ¸ ìƒì„± |

### 4. ëª¨ë‹ˆí„°ë§ (`backend/core/`)

| ì»´í¬ë„ŒíŠ¸ | ìœ í˜• | ìš©ë„ |
|----------|------|------|
| `http_requests_total` | Counter | ìš”ì²­ ìˆ˜ ì¹´ìš´íŠ¸ |
| `http_request_duration_seconds` | Histogram | Latency ë¶„í¬ |
| `dialogue_sessions_total` | Counter | ì„¸ì…˜ ì‹œì‘ ìˆ˜ |
| `retrieval_duration_seconds` | Histogram | Retrieval ì„±ëŠ¥ |
| `llm_calls_total` | Counter | LLM API í˜¸ì¶œ (statusë³„) |
| `evidence_count` | Histogram | Evidence ìˆ˜ ë¶„í¬ |

### 5. í”„ë¡ íŠ¸ì—”ë“œ (`frontend/src/`)

| íŒŒì¼ | ì—­í•  |
|------|------|
| `App.vue` | ë£¨íŠ¸ ì»´í¬ë„ŒíŠ¸ |
| `components/ChatBot.vue` | ëŒ€í™” UI, API í†µì‹ , ê²°ê³¼ í‘œì‹œ |
| `api.js` | Axios ê¸°ë°˜ API í´ë¼ì´ì–¸íŠ¸ |
| `config.js` | í™˜ê²½ ì„¤ì • |

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ìºì‹± ì „ëµ

```python
class DialogueSession:
    def __init__(self):
        self.scored_df = None  # ìºì‹œ
        self.factor_counts = None  # ìºì‹œ
    
    def _finalize(self):
        # ì²« í˜¸ì¶œ ì‹œì—ë§Œ ê³„ì‚°, ì´í›„ ì¬ì‚¬ìš©
        if self.scored_df is None:
            self.scored_df, self.factor_counts = compute_scores(...)
```

### 2. ë°°ì¹˜ ì²˜ë¦¬

```python
# í•œ ë²ˆì— ëª¨ë“  ë¦¬ë·° ìŠ¤ì½”ì–´ ê³„ì‚°
scored_df = compute_review_factor_scores(reviews_df, factors)

# ê°œë³„ ê³„ì‚° ëŒ€ì‹  ë²¡í„°í™”
df['score'] = df.apply(lambda row: score_function(row), axis=1)
```

### 3. ì¸ë±ì‹±

```python
# Factor map ìƒì„± (O(1) ì¡°íšŒ)
self.factors_map = {f.factor_key: f for f in self.factors}
self.factors_by_id = {f.factor_id: f for f in self.factors}
```

---

## ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 1. API Key ê´€ë¦¬

```bash
# .env íŒŒì¼ (Git ì œì™¸)
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=...

# .gitignore
.env
*.key
*.pem
```

### 2. CORS ì„¤ì •

```python
# backend/core/settings.py
ALLOWED_ORIGINS = [
    "http://localhost:3000",
    "https://yourdomain.com",
]
```

### 3. ë°ì´í„° ê²©ë¦¬

- ì„¸ì…˜ë³„ ë…ë¦½ DialogueSession ì¸ìŠ¤í„´ìŠ¤
- ì‚¬ìš©ì ë°ì´í„° í˜¼ì¬ ë°©ì§€

---

## í™•ì¥ ê°€ëŠ¥ì„±

### 1. ìƒˆ ì œí’ˆ ì¹´í…Œê³ ë¦¬ ì¶”ê°€

```bash
# 1. ë¦¬ë·° ìˆ˜ì§‘ (Selenium WebDriver ì‚¬ìš©)
python scripts/collect_smartstore_reviews.py "https://brand.naver.com/..." \
    --category new_category \
    --product-name "product_name" \
    --max-reviews 100

# 2. Factor ë¶„ì„
python scripts/analyze_product_reviews.py --category new_category

# 3. Question ìƒì„± (ìˆ˜ë™ CSV ì‘ì„±)
# data/question/reg_question.csvì— ì¶”ê°€
```

### 2. ìƒˆ LLM Provider ì¶”ê°€

```python
# 1. í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
class NewLLMClient(BaseLLMClient):
    def generate_summary(self, ...):
        # API í˜¸ì¶œ ë¡œì§
        pass

# 2. Factoryì— ë“±ë¡
class LLMFactory:
    @staticmethod
    def create_client(provider, ...):
        if provider == "newllm":
            return NewLLMClient(...)
```

### 3. ë‹¤êµ­ì–´ ì§€ì›

```python
# 1. ì–¸ì–´ë³„ ì •ê·œí™” í•¨ìˆ˜
def normalize(text, lang='ko'):
    if lang == 'ko':
        # í•œê¸€ ì²˜ë¦¬
    elif lang == 'en':
        # ì˜ì–´ ì²˜ë¦¬

# 2. ì–¸ì–´ë³„ Factor/Question
# data/factor/reg_factor_en.csv
```

---

## ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½

| ê³„ì¸µ | ê¸°ìˆ  | ë²„ì „ |
|------|------|------|
| **ë°±ì—”ë“œ** | FastAPI | 0.115.0 |
| | Python | 3.11+ |
| | Pandas | 2.3.3 |
| | Uvicorn | 0.32.0 |
| **í”„ë¡ íŠ¸ì—”ë“œ** | Vue.js | 3.x |
| | Vite | 5.x |
| | Axios | 1.x |
| **LLM** | OpenAI | gpt-4o-mini |
| | Google Gemini | gemini-1.5-flash |
| | Anthropic Claude | claude-3-5-sonnet |
| **ëª¨ë‹ˆí„°ë§** | Prometheus | 2.48.1 |
| | Grafana | 10.2.3 |
| | prometheus-client | 0.20.0+ |
| **ë°°í¬** | Docker | 24.x |
| | Docker Compose | 2.x |
| | Kubernetes | 1.28+ (ì„ íƒ) |

---

## ì°¸ê³  ë¬¸ì„œ

- [README.md](../README.md) - í”„ë¡œì íŠ¸ ê°œìš”
- [MONITORING_ARCHITECTURE.md](MONITORING_ARCHITECTURE.md) - ëª¨ë‹ˆí„°ë§ ì•„í‚¤í…ì²˜ ë° ë°°í¬ ê°€ì´ë“œ
- [LLM_SETUP.md](LLM_SETUP.md) - LLM ì„¤ì • ê°€ì´ë“œ
- [SMARTSTORE_REVIEW_COLLECTION.md](SMARTSTORE_REVIEW_COLLECTION.md) - í¬ë¡¤ë§ ê°€ì´ë“œ
- [ARCHITECTURE_OLD.md](ARCHITECTURE_OLD.md) - ì´ì „ ì•„í‚¤í…ì²˜ ë¬¸ì„œ (ì°¸ê³ ìš©)
- [DEV_ENV_SETUP.md](DEV_ENV_SETUP.md) - ê°œë°œ í™˜ê²½ ì„¤ì •
- [CONTRIBUTING.md](CONTRIBUTING.md) - ê¸°ì—¬ ê°€ì´ë“œ
- [PROJECT_STATUS.md](PROJECT_STATUS.md) - í”„ë¡œì íŠ¸ í˜„í™©

---

**ë¬¸ì„œ ë²„ì „**: 2.0  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2026-01-04  
**ì‘ì„±ì**: ReviewLens Team
