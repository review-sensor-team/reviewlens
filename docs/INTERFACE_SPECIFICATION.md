# ReviewLens ì¸í„°í˜ì´ìŠ¤ ëª…ì„¸ì„œ

ê° ê°œë°œ ì˜ì—­ ê°„ ì£¼ê³ ë°›ëŠ” ë°ì´í„° ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

## ëª©ì°¨

- [1. í”„ë¡ íŠ¸ì—”ë“œ â†” ë°±ì—”ë“œ API](#1-í”„ë¡ íŠ¸ì—”ë“œ--ë°±ì—”ë“œ-api)
- [2. ë°±ì—”ë“œ API â†” Dialogue Engine](#2-ë°±ì—”ë“œ-api--dialogue-engine)
- [3. Dialogue Engine â†” LLM Services](#3-dialogue-engine--llm-services)
- [4. Dialogue Engine â†” Retrieval Pipeline](#4-dialogue-engine--retrieval-pipeline)
- [5. í¬ë¡¤ëŸ¬ â†” ë°±ì—”ë“œ](#5-í¬ë¡¤ëŸ¬--ë°±ì—”ë“œ)
- [6. ë°±ì—”ë“œ â†” Monitoring](#6-ë°±ì—”ë“œ--monitoring)

---

## 1. í”„ë¡ íŠ¸ì—”ë“œ â†” ë°±ì—”ë“œ API

### 1.1 ë¦¬ë·° ìˆ˜ì§‘ (POST /api/collect-reviews)

**ìš”ì²­ (Request)**:
```typescript
interface CollectReviewsRequest {
  product_url: string;           // ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ìƒí’ˆ URL
  max_reviews?: number;          // ìµœëŒ€ ìˆ˜ì§‘ ë¦¬ë·° ìˆ˜ (ê¸°ë³¸ê°’: 100)
  sort_by_low_rating?: boolean;  // ë‚®ì€ í‰ì  ìš°ì„  ì •ë ¬ (ê¸°ë³¸ê°’: true)
  category?: string;             // ì¹´í…Œê³ ë¦¬ ê°•ì œ ì§€ì • (ì„ íƒì‚¬í•­)
}
```

**ì‘ë‹µ (Response)**:
```typescript
interface CollectReviewsResponse {
  success: boolean;
  message: string;
  session_id?: string;           // ìƒì„±ëœ ì„¸ì…˜ ID
  reviews: Review[];
  total_count: number;
  
  // ì¹´í…Œê³ ë¦¬ ê°ì§€ ì •ë³´
  detected_category?: string;    // ê°ì§€ëœ ì¹´í…Œê³ ë¦¬ í‚¤
  category_confidence: 'high' | 'low' | 'failed';
  available_categories?: Array<{
    key: string;                 // ì˜ˆ: 'appliance_induction'
    name: string;                // ì˜ˆ: 'ì¸ë•ì…˜'
  }>;
  
  // ìƒí’ˆ ì •ë³´
  product_name?: string;         // í˜ì´ì§€ ì œëª©ì—ì„œ ì¶”ì¶œ
}

interface Review {
  review_id: number;
  rating?: number;               // 1-5
  text: string;
  created_at: string;            // ISO 8601 format
  factor_matches?: FactorMatch[];
}

interface FactorMatch {
  factor_id?: number;
  factor_key: string;
  display_name: string;
  sentences: string[];           // ë§¤ì¹­ëœ ë¬¸ì¥ë“¤
  matched_terms: string[];       // ë§¤ì¹­ëœ í‚¤ì›Œë“œë“¤
}
```

**ì—ëŸ¬ ì‘ë‹µ**:
```typescript
interface ErrorResponse {
  detail: string;                // ì—ëŸ¬ ë©”ì‹œì§€
}
```

**HTTP ìƒíƒœ ì½”ë“œ**:
- `200 OK`: ì„±ê³µ
- `400 Bad Request`: ì˜ëª»ëœ URL í˜•ì‹
- `500 Internal Server Error`: í¬ë¡¤ë§ ì‹¤íŒ¨

---

### 1.2 ì„¸ì…˜ ì‹œì‘ (POST /api/chat/start)

**ìš”ì²­**:
```typescript
interface SessionStartRequest {
  category: string;              // ì¹´í…Œê³ ë¦¬ í‚¤ (ì˜ˆ: 'robot_cleaner')
}
```

**ì‘ë‹µ**:
```typescript
interface SessionStartResponse {
  session_id: string;            // ìƒì„±ëœ ì„¸ì…˜ ID (UUID)
  message: string;               // í™˜ì˜ ë©”ì‹œì§€
}
```

**ì—ëŸ¬**:
- `400 Bad Request`: ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬
- `500 Internal Server Error`: ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨

---

### 1.3 ëŒ€í™” ë©”ì‹œì§€ (POST /api/chat/message)

**ìš”ì²­**:
```typescript
interface ChatRequest {
  session_id: string;            // ì„¸ì…˜ ID
  message: string;               // ì‚¬ìš©ì ë©”ì‹œì§€
}
```

**ì‘ë‹µ**:
```typescript
interface ChatResponse {
  session_id: string;
  bot_message?: string;          // ë´‡ ì‘ë‹µ ë©”ì‹œì§€
  is_final: boolean;             // ëŒ€í™” ì¢…ë£Œ ì—¬ë¶€
  top_factors: FactorScore[];
  
  // LLM ìš”ì•½ (is_final=trueì¼ ë•Œë§Œ)
  llm_context?: {
    top_factors_summary: Array<{
      factor_key: string;
      display_name: string;
      score: number;
      description: string;
    }>;
    overall_summary: string;
    recommendations: string[];
    evidence_stats: {
      negative: number;
      mixed: number;
      positive: number;
    };
  };
  
  // ê´€ë ¨ ë¦¬ë·° ì •ë³´
  related_reviews?: {
    [factor_key: string]: {
      count: number;
      examples: string[];        // ìµœëŒ€ 3ê°œ
    };
  };
  
  // ì§ˆë¬¸ ì •ë³´ (is_final=falseì¼ ë•Œ)
  question_id?: string;
  answer_type?: 'no_choice' | 'single_choice';
  choices?: string;              // 'ì˜ˆ|ì•„ë‹ˆì˜¤|ì˜ ëª¨ë¥´ê² ìŒ'
}

interface FactorScore {
  factor_key: string;
  factor_id?: number;
  score: number;
}
```

**ì—ëŸ¬**:
- `404 Not Found`: ì„¸ì…˜ IDê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ
- `400 Bad Request`: ì˜ëª»ëœ ìš”ì²­ í˜•ì‹
- `500 Internal Server Error`: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜

---

### 1.4 ë©”íŠ¸ë¦­ ë…¸ì¶œ (GET /metrics)

**ìš”ì²­**: ì—†ìŒ

**ì‘ë‹µ**: Prometheus text format
```text
# HELP http_requests_total Total HTTP requests
# TYPE http_requests_total counter
http_requests_total{method="POST",endpoint="/api/chat/message",status_code="200"} 42

# HELP http_request_duration_seconds HTTP request latency
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{method="POST",endpoint="/api/chat/message",le="0.1"} 10
...
```

---

## 2. ë°±ì—”ë“œ API â†” Dialogue Engine

### 2.1 DialogueSession ì´ˆê¸°í™”

**Python ì¸í„°í˜ì´ìŠ¤**:
```python
from backend.pipeline.dialogue import DialogueSession

# ìƒì„±
session = DialogueSession(
    category: str,              # ì¹´í…Œê³ ë¦¬ í‚¤
    data_dir: str,              # ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
    reviews_df: pd.DataFrame    # ë¦¬ë·° DataFrame
)

# reviews_df êµ¬ì¡°
# columns: ['review_id', 'rating', 'text', 'created_at', ...]
# dtypes: review_id (int), rating (int), text (str), created_at (str)
```

**DialogueSession ì†ì„±**:
```python
session.session_id: str                    # UUID
session.category: str                      # ì¹´í…Œê³ ë¦¬ í‚¤
session.turn_count: int                    # í˜„ì¬ í„´ ìˆ˜
session.factors: List[Factor]              # ë¡œë“œëœ Factor ë¦¬ìŠ¤íŠ¸
session.cumulative_scores: Dict[str, float]  # ëˆ„ì  ì ìˆ˜
session.prev_top3: Set[str]                # ì´ì „ Top 3 factor keys
session.stability_hits: int                # ìˆ˜ë ´ ì¹´ìš´í„°
```

---

### 2.2 ëŒ€í™” í„´ ì²˜ë¦¬ (step)

**í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜**:
```python
def step(user_message: str) -> BotTurn
```

**BotTurn êµ¬ì¡°**:
```python
@dataclass
class BotTurn:
    question_text: Optional[str]           # ë‹¤ìŒ ì§ˆë¬¸
    top_factors: List[Tuple[str, float]]   # [(factor_key, score), ...]
    is_final: bool                         # ëŒ€í™” ì™„ë£Œ ì—¬ë¶€
    llm_context: Optional[Dict]            # LLM ìš”ì•½ (is_final=Trueì¼ ë•Œ)
    question_id: Optional[str]             # ì§ˆë¬¸ ID
    answer_type: Optional[str]             # 'no_choice' | 'single_choice'
    choices: Optional[str]                 # ì„ íƒì§€
```

**ì²˜ë¦¬ íë¦„**:
1. ë©”ì‹œì§€ ì •ê·œí™” (`normalize(user_message)`)
2. Factor ë§¤ì¹­ ë° ì ìˆ˜ ëˆ„ì 
3. Top 3 ì¶”ì¶œ
4. ìˆ˜ë ´ ì²´í¬ (Jaccard similarity > 0.7, stability_hits >= 3)
5. ìˆ˜ë ´ ì‹œ: `_finalize()` í˜¸ì¶œ
6. ë¯¸ìˆ˜ë ´ ì‹œ: ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±

---

### 2.3 ìµœì¢… ë¶„ì„ (_finalize)

**í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜**:
```python
def _finalize(top_factors: List[Tuple[str, float]]) -> BotTurn
```

**ë‚´ë¶€ ì²˜ë¦¬**:
1. `compute_review_factor_scores()` - Factor ì ìˆ˜ ê³„ì‚°
2. `retrieve_evidence_reviews()` - Evidence ìˆ˜ì§‘
3. `_generate_llm_summary()` - LLM ìš”ì•½ ìƒì„±

**llm_context êµ¬ì¡°**:
```python
{
    "top_factors_summary": [
        {
            "factor_key": str,
            "display_name": str,
            "score": float,
            "description": str
        }
    ],
    "overall_summary": str,         # ì „ì²´ ìš”ì•½
    "recommendations": [str],        # ì²´í¬í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
    "evidence_stats": {
        "negative": int,
        "mixed": int,
        "positive": int
    }
}
```

---

## 3. Dialogue Engine â†” LLM Services

### 3.1 LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„± (Factory Pattern)

**Python ì¸í„°í˜ì´ìŠ¤**:
```python
from backend.services.llm_factory import LLMFactory

client = LLMFactory.create_client(
    provider: str,                 # 'openai' | 'gemini' | 'claude'
    api_key: Optional[str] = None,
    model: Optional[str] = None
)
```

---

### 3.2 ìš”ì•½ ìƒì„± (generate_summary)

**í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜**:
```python
def generate_summary(
    top_factors: List[Tuple[str, float]],
    evidence_reviews: Dict[str, List[Dict]],
    product_name: str,
    category_name: str,
    total_turns: int,
    conversation_history: Optional[List[str]] = None
) -> str
```

**top_factors êµ¬ì¡°**:
```python
[
    ("noise", 4.5),
    ("suction", 3.2),
    ("battery", 2.8)
]
```

**evidence_reviews êµ¬ì¡°**:
```python
{
    "noise": [
        {
            "text": str,
            "rating": int,
            "label": "NEG" | "MIX" | "POS",
            "score": float
        },
        ...
    ],
    "suction": [...],
    ...
}
```

**ë°˜í™˜ê°’**:
```python
# ì„±ê³µ ì‹œ
"""
ğŸ” í•µì‹¬ í›„íšŒ ìš”ì¸ ë¶„ì„ (Top 5)

1. ì†ŒìŒ ë¬¸ì œ (ì ìˆ˜: 4.5)
   - ì„¤ëª…...

2. í¡ì…ë ¥ (ì ìˆ˜: 3.2)
   - ì„¤ëª…...

âœ… êµ¬ë§¤ ì „ ì²´í¬í¬ì¸íŠ¸:
- ì²´í¬í¬ì¸íŠ¸ 1
- ì²´í¬í¬ì¸íŠ¸ 2

ğŸ’¡ í•œ ì¤„ ì¡°ì–¸: ...
"""

# ì‹¤íŒ¨ ì‹œ (fallback)
"ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒìœ„ ìš”ì¸ì€ {factor1}, {factor2}, {factor3}ì…ë‹ˆë‹¤."
```

**ì—ëŸ¬ ì²˜ë¦¬**:
- API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ: fallback ë©”ì‹œì§€ ë°˜í™˜
- Timeout: 30ì´ˆ í›„ fallback
- ë©”íŠ¸ë¦­ ê¸°ë¡: `llm_calls_total{provider, status='error'}`

---

## 4. Dialogue Engine â†” Retrieval Pipeline

### 4.1 ë¦¬ë·° ìŠ¤ì½”ì–´ë§ (compute_review_factor_scores)

**í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜**:
```python
def compute_review_factor_scores(
    df: pd.DataFrame,
    factors: List[Factor],
    compute_top_per_review: bool = True
) -> Tuple[pd.DataFrame, Dict[str, int]]
```

**ì…ë ¥ DataFrame êµ¬ì¡°**:
```python
# columns: ['review_id', 'rating', 'text', 'created_at']
# ì˜ˆì‹œ í–‰:
{
    'review_id': 12345,
    'rating': 3,
    'text': 'ì†ŒìŒì´ ë„ˆë¬´ í¬ê³  ì‹œë„ëŸ¬ì›Œìš”',
    'created_at': '2026-01-01T12:00:00'
}
```

**ì¶œë ¥ DataFrame êµ¬ì¡°**:
```python
# ì…ë ¥ ì»¬ëŸ¼ + ì¶”ê°€ ì»¬ëŸ¼
columns = [
    'review_id', 'rating', 'text', 'created_at',
    'score_f1',           # Factor ID 1 ì ìˆ˜
    'score_f2',           # Factor ID 2 ì ìˆ˜
    'score_noise',        # Factor key ì ìˆ˜ (í•˜ìœ„ í˜¸í™˜)
    'has_neg_noise',      # negation í”Œë˜ê·¸ (bool)
    'top_factors',        # List[str] - Top 3 factor keys
    'top_factor_scores'   # List[Tuple[str, float]]
]
```

**factor_counts êµ¬ì¡°**:
```python
{
    "noise": 45,          # 'noise' factorê°€ ë§¤ì¹­ëœ ë¦¬ë·° ìˆ˜
    "suction": 32,
    "battery": 28
}
```

---

### 4.2 ì¦ê±° ë¦¬ë·° ê²€ìƒ‰ (retrieve_evidence_reviews)

**í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜**:
```python
def retrieve_evidence_reviews(
    scored_df: pd.DataFrame,
    top_factors: List[Tuple[str, float]],
    max_per_factor: int = 6
) -> Dict[str, List[Dict]]
```

**top_factors ì…ë ¥**:
```python
[
    ("noise", 4.5),
    ("suction", 3.2),
    ("battery", 2.8),
    ("cleaning_quality", 1.9),
    ("design", 1.5)
]
```

**ë°˜í™˜ê°’ êµ¬ì¡°**:
```python
{
    "noise": [
        {
            "text": "ì†ŒìŒì´ ë„ˆë¬´ ì»¤ì„œ...",
            "rating": 2,
            "label": "NEG",      # NEG | MIX | POS
            "score": 4.2,
            "review_id": 12345,
            "created_at": "2026-01-01T12:00:00"
        },
        # NEG: 3ê°œ, MIX: 2ê°œ, POS: 1ê°œ (Rank 0 quota)
    ],
    "suction": [
        # NEG: 2ê°œ, MIX: 2ê°œ, POS: 1ê°œ (Rank 1 quota)
    ],
    ...
}
```

**Quota ì‹œìŠ¤í…œ**:
- Rank 0 (Top 1): NEG 3ê°œ, MIX 2ê°œ, POS 1ê°œ
- Rank 1 (Top 2): NEG 2ê°œ, MIX 2ê°œ, POS 1ê°œ
- Rank 2+ (Top 3-5): NEG 2ê°œ, MIX 2ê°œ, POS 1ê°œ

**Label ë¶„ë¥˜ ë¡œì§**:
```python
# score >= 2.0 and rating <= 3 â†’ NEG
# score >= 1.0 and rating == 4 â†’ MIX
# score >= 1.0 and rating == 5 â†’ POS
```

---

## 5. í¬ë¡¤ëŸ¬ â†” ë°±ì—”ë“œ

### 5.1 SmartStoreCollector ì¸í„°í˜ì´ìŠ¤

**Python ì¸í„°í˜ì´ìŠ¤**:
```python
from backend.app.collector import SmartStoreCollector

collector = SmartStoreCollector(
    headless: bool = True,
    timeout: int = 30
)

result = collector.collect_reviews(
    product_url: str,
    max_reviews: int = 100,
    sort_by_low_rating: bool = True
)
```

**ë°˜í™˜ê°’ êµ¬ì¡°**:
```python
{
    "success": bool,
    "product_name": str,          # í˜ì´ì§€ ì œëª©
    "total_collected": int,
    "reviews": [
        {
            "review_id": int,     # ê³ ìœ  ID (í•´ì‹œ ê¸°ë°˜)
            "rating": int,        # 1-5
            "text": str,
            "created_at": str,    # ISO 8601
            "reviewer": str       # ì‘ì„±ì (ì„ íƒì‚¬í•­)
        },
        ...
    ],
    "error": Optional[str]        # ì—ëŸ¬ ë©”ì‹œì§€
}
```

**ì—ëŸ¬ íƒ€ì…**:
- `InvalidURLError`: ì˜ëª»ëœ URL í˜•ì‹
- `PageLoadError`: í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨
- `NoReviewsFoundError`: ë¦¬ë·°ê°€ ì—†ìŒ
- `SeleniumError`: WebDriver ì˜¤ë¥˜

---

### 5.2 FactorAnalyzer ì¸í„°í˜ì´ìŠ¤

**Python ì¸í„°í˜ì´ìŠ¤**:
```python
from backend.app.collector.factor_analyzer import FactorAnalyzer

analyzer = FactorAnalyzer()

matches = analyzer.analyze_reviews(
    reviews: List[Dict],
    factors: List[Factor]
) -> List[Dict]
```

**ì…ë ¥ reviews**:
```python
[
    {
        "review_id": 12345,
        "text": "ì†ŒìŒì´ ë„ˆë¬´ í¬ê³ ...",
        "rating": 3
    },
    ...
]
```

**ì¶œë ¥ êµ¬ì¡°**:
```python
[
    {
        "review_id": 12345,
        "factor_matches": [
            {
                "factor_key": "noise",
                "factor_id": 1,
                "display_name": "ì†ŒìŒ",
                "sentences": ["ì†ŒìŒì´ ë„ˆë¬´ í¬ê³ "],
                "matched_terms": ["ì†ŒìŒ", "í¬"]
            }
        ]
    },
    ...
]
```

---

## 6. ë°±ì—”ë“œ â†” Monitoring

### 6.1 Prometheus ë©”íŠ¸ë¦­ ë…¸ì¶œ

**Endpoint**: `GET /metrics`

**ë©”íŠ¸ë¦­ íƒ€ì…**:

#### Counter (ëˆ„ì ê°’)
```python
http_requests_total{method, endpoint, status_code}
dialogue_sessions_total{category}
dialogue_turns_total{category}
dialogue_completions_total
llm_calls_total{provider, status}
errors_total{error_type}
```

#### Histogram (ë¶„í¬)
```python
http_request_duration_seconds{method, endpoint}
retrieval_duration_seconds{category}
scoring_duration_seconds{category}
llm_duration_seconds{provider}
evidence_count
```

---

### 6.2 ë©”íŠ¸ë¦­ ê³„ì¸¡ (Instrumentation)

**HTTP ë¯¸ë“¤ì›¨ì–´**:
```python
from backend.core.metrics import http_requests_total, http_request_duration_seconds

# ìë™ ê¸°ë¡
http_requests_total.labels(
    method="POST",
    endpoint="/api/chat/message",
    status_code=200
).inc()

http_request_duration_seconds.labels(
    method="POST",
    endpoint="/api/chat/message"
).observe(0.123)  # ì´ˆ ë‹¨ìœ„
```

**Pipeline ê³„ì¸¡**:
```python
from backend.core.metrics import Timer, retrieval_duration_seconds

with Timer(retrieval_duration_seconds, {'category': 'robot_cleaner'}):
    evidence = retrieve_evidence_reviews(...)
```

**LLM ê³„ì¸¡**:
```python
from backend.core.metrics import llm_calls_total, llm_duration_seconds, Timer

with Timer(llm_duration_seconds, {'provider': 'openai'}):
    summary = llm_client.generate_summary(...)

# ì„±ê³µ ì‹œ
llm_calls_total.labels(provider='openai', status='success').inc()

# ì‹¤íŒ¨ ì‹œ
llm_calls_total.labels(provider='openai', status='error').inc()
llm_calls_total.labels(provider='openai', status='fallback').inc()
```

---

### 6.3 Grafana ì¿¼ë¦¬ (PromQL)

**HTTP Latency (p50/p95/p99)**:
```promql
# p50
histogram_quantile(0.5, rate(http_request_duration_seconds_bucket[5m]))

# p95
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# p99
histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))
```

**ì—ëŸ¬ìœ¨**:
```promql
# 5xx ì—ëŸ¬ìœ¨ (%)
sum(rate(http_requests_total{status_code=~"5.."}[5m])) 
/ 
sum(rate(http_requests_total[5m])) 
* 100
```

**LLM ì„±ê³µë¥ **:
```promql
# LLM API ì„±ê³µë¥  (%)
sum(rate(llm_calls_total{status="success"}[5m])) 
/ 
sum(rate(llm_calls_total[5m])) 
* 100
```

---

## ë¶€ë¡: Factor ë°ì´í„° êµ¬ì¡°

### Factor í´ë˜ìŠ¤

**Python ì •ì˜**:
```python
@dataclass
class Factor:
    factor_id: int                    # ê³ ìœ  ID
    category: str                     # ì¹´í…Œê³ ë¦¬ í‚¤
    factor_key: str                   # Factor í‚¤ (ì˜ˆ: 'noise')
    display_name: str                 # í‘œì‹œëª… (ì˜ˆ: 'ì†ŒìŒ')
    weight: float                     # ê°€ì¤‘ì¹˜ (1.0-3.0)
    anchor_terms: List[str]           # í•µì‹¬ í‚¤ì›Œë“œ
    context_terms: List[str]          # ì—°ê´€ í‚¤ì›Œë“œ
    negation_terms: List[str]         # ë°˜ì „ í‘œí˜„
```

**CSV í˜•ì‹** (`data/factor/reg_factor.csv`):
```csv
factor_id,category,factor_key,display_name,weight,anchor_terms,context_terms,negation_terms
1,robot_cleaner,noise,ì†ŒìŒ,1.5,"ì†ŒìŒ|ì‹œë„ëŸ¬|ë– ë“¤","ì¡°ìš©|ì •ìˆ™","ì¡°ìš©í•˜|ê´œì°®"
2,robot_cleaner,suction,í¡ì…ë ¥,2.0,"í¡ì…|ë¹¨ì•„ë“¤","ì²­ì†Œë ¥|íŒŒì›Œ","ì•½í•˜|ë¶€ì¡±"
```

**ì ìˆ˜ ê³„ì‚° ë¡œì§**:
```python
score = 0.0

# anchor_terms ë§¤ì¹­: +1.0
if any(term in normalized_text for term in factor.anchor_terms):
    score += 1.0

# context_terms ë§¤ì¹­: +0.3
if any(term in normalized_text for term in factor.context_terms):
    score += 0.3

# negation_terms ë§¤ì¹­: ì ìˆ˜ ë°˜ì˜ X, has_neg í”Œë˜ê·¸ë§Œ ì„¤ì •
has_negation = any(term in normalized_text for term in factor.negation_terms)

# weight ê³±ì…ˆ
weighted_score = score * factor.weight

# rating multiplier: 1.0 + (5 - rating) * 0.2
# rating=1 â†’ 1.8x, rating=5 â†’ 1.0x
final_score = weighted_score * rating_multiplier
```

---

## ë¶€ë¡: ì—ëŸ¬ ì²˜ë¦¬ ê°€ì´ë“œ

### HTTP ì—ëŸ¬ ì½”ë“œ

| ì½”ë“œ | ìƒí™© | ì‘ë‹µ ì˜ˆì‹œ |
|------|------|----------|
| `200 OK` | ì •ìƒ ì²˜ë¦¬ | `{"success": true, ...}` |
| `400 Bad Request` | ì˜ëª»ëœ ìš”ì²­ | `{"detail": "Invalid URL format"}` |
| `404 Not Found` | ì„¸ì…˜ ì—†ìŒ | `{"detail": "Session not found"}` |
| `422 Unprocessable Entity` | Validation ì‹¤íŒ¨ | Pydantic ì—ëŸ¬ |
| `500 Internal Server Error` | ì„œë²„ ì˜¤ë¥˜ | `{"detail": "Internal error"}` |
| `503 Service Unavailable` | LLM API ì¥ì•  | `{"detail": "LLM service unavailable"}` |

### ì¬ì‹œë„ ì „ëµ

**í¬ë¡¤ëŸ¬**:
- í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: 3íšŒ ì¬ì‹œë„ (5ì´ˆ ê°„ê²©)
- Element not found: 2íšŒ ì¬ì‹œë„ (2ì´ˆ ê°„ê²©)
- Timeout: ì¬ì‹œë„ ì—†ìŒ (ì¦‰ì‹œ ì‹¤íŒ¨)

**LLM API**:
- Rate limit: ì§€ìˆ˜ ë°±ì˜¤í”„ (1s â†’ 2s â†’ 4s)
- Network error: 3íšŒ ì¬ì‹œë„
- Timeout: fallback ë©”ì‹œì§€ ë°˜í™˜

**Prometheus Scrape**:
- ì‹¤íŒ¨ ì‹œ: ë‹¤ìŒ intervalê¹Œì§€ ëŒ€ê¸° (15ì´ˆ)
- ì—°ì† ì‹¤íŒ¨ ì‹œ: Alert ë°œìƒ

---

## ë³€ê²½ ì´ë ¥

| ë²„ì „ | ë‚ ì§œ | ë³€ê²½ ë‚´ìš© |
|------|------|----------|
| 1.0 | 2026-01-04 | ì´ˆê¸° ì‘ì„± |

---

**ë¬¸ì„œ ì‘ì„±ì**: ReviewLens Team  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2026-01-04
