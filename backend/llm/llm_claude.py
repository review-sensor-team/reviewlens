"""
Anthropic Claude LLM ν΄λΌμ΄μ–ΈνΈ
"""
import logging
from typing import List, Dict, Any, Optional
from .llm_base import BaseLLMClient

logger = logging.getLogger(__name__)


class ClaudeClient(BaseLLMClient):
    """Anthropic Claude API ν΄λΌμ΄μ–ΈνΈ"""
    
    def __init__(self, api_key: str, model: str = "claude-3-5-sonnet-20241022", temperature: float = 0.7, max_tokens: int = 2000):
        self.api_key = api_key
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        if not api_key:
            logger.warning("Anthropic API keyκ°€ μ„¤μ •λμ§€ μ•μ•μµλ‹λ‹¤. κΈ°λ³Έ λ©”μ‹μ§€λ¥Ό λ°ν™ν•©λ‹λ‹¤.")
            self.client = None
        else:
            try:
                from anthropic import Anthropic
                self.client = Anthropic(api_key=api_key)
                logger.info(f"Claude ν΄λΌμ΄μ–ΈνΈ μ΄κΈ°ν™” μ™„λ£: model={model}")
            except Exception as e:
                logger.error(f"Claude ν΄λΌμ΄μ–ΈνΈ μ΄κΈ°ν™” μ‹¤ν¨: {e}")
                self.client = None
    
    def generate_summary(
        self, 
        top_factors: List[tuple],
        evidence_reviews: List[Dict[str, Any]],
        total_turns: int,
        category_name: str,
        product_name: str = "μ΄ μ ν’",
        dialogue_history: Optional[List[Dict[str, str]]] = None
    ) -> str:
        """μµμΆ… λ¶„μ„ μ”μ•½ μƒμ„±"""
        
        if not self.client:
            return self._get_fallback_summary(top_factors, category_name, product_name)
        
        # ν”„λ΅¬ν”„νΈ κµ¬μ„±
        system_prompt, user_prompt = self._build_prompts(
            top_factors, evidence_reviews, total_turns, category_name, product_name, dialogue_history
        )
        
        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": user_prompt}
                ]
            )
            
            summary = response.content[0].text.strip()
            logger.info(f"Claude μ”μ•½ μƒμ„± μ™„λ£: {len(summary)}μ")
            return summary
            
        except Exception as e:
            logger.error(f"Claude API νΈμ¶ μ‹¤ν¨: {e}")
            return self._get_fallback_summary(top_factors, category_name, product_name)
    
    def _build_prompts(
        self,
        top_factors: List[tuple],
        evidence_reviews: List[Dict[str, Any]],
        total_turns: int,
        category_name: str,
        product_name: str,
        dialogue_history: Optional[List[Dict[str, str]]] = None
    ) -> tuple:
        """μ‹μ¤ν…/μ μ € ν”„λ΅¬ν”„νΈ κµ¬μ„±"""
        
        system_prompt = """λ‹Ήμ‹ μ€ μ ν’ λ¦¬λ·° λ¶„μ„ μ „λ¬Έκ°€μ…λ‹λ‹¤. 
κµ¬λ§¤μλ“¤μ ν›„ν μ”μΈμ„ λ¶„μ„ν•μ—¬ μ‹¤μ©μ μ΄κ³  κµ¬μ²΄μ μΈ μ΅°μ–Έμ„ μ κ³µν•©λ‹λ‹¤.
μΉκ·Όν•μ§€λ§ μ „λ¬Έμ μΈ ν†¤μΌλ΅, 300-500μ λ¶„λ‰μ μ”μ•½μ„ μ‘μ„±ν•©λ‹λ‹¤."""
        
        # μƒμ„ μ”μΈ μ •λ¦¬
        factors_text = "\n".join([
            f"{i+1}. {factor_key} (μ μ: {score:.2f})"
            for i, (factor_key, score) in enumerate(top_factors[:5])
        ])
        
        # λ€ν™” λ‚΄μ© μ •λ¦¬
        dialogue_text = ""
        if dialogue_history:
            dialogue_lines = []
            for turn in dialogue_history:
                role = turn.get('role', '')
                text = turn.get('message', '')
                if role == 'user':
                    dialogue_lines.append(f"μ‚¬μ©μ: {text}")
                elif role == 'assistant':
                    dialogue_lines.append(f"μ–΄μ‹μ¤ν„΄νΈ: {text}")
            dialogue_text = "\n".join(dialogue_lines)
        
        # λ¨λ“  μ¦κ±° λ¦¬λ·° ν¬ν•¨ (μƒμ„ 5κ°κ°€ μ•„λ‹ μ „μ²΄)
        evidence_text = ""
        for i, rev in enumerate(evidence_reviews, 1):
            label = rev.get('label', 'NEU')
            rating = rev.get('rating', 0)
            excerpt = rev.get('excerpt', '')  # μ „μ²΄ λ¦¬λ·° λ‚΄μ© μ‚¬μ©
            evidence_text += f"{i}. [{label}] {rating}μ  - {excerpt}\n"
        
        # User Prompt κµ¬μ„±
        user_prompt_parts = [
            f"**μ ν’ μ •λ³΄**",
            f"- μΉ΄ν…κ³ λ¦¬: {category_name}",
            f"- μ ν’λ…: {product_name}",
            f"- λ¶„μ„ λ€ν™” ν„΄: {total_turns}ν„΄",
            ""
        ]
        
        if dialogue_text:
            user_prompt_parts.extend([
                f"**λ€ν™” λ‚΄μ©**",
                dialogue_text,
                ""
            ])
        
        user_prompt_parts.extend([
            f"**μ£Όμ” ν›„ν μ”μΈ (μƒμ„ 5κ°)**",
            factors_text,
            "",
            f"**μ¦κ±° λ¦¬λ·° μ „μ²΄ ({len(evidence_reviews)}κ°)**",
            evidence_text,
            "",
            "λ‹¤μ ν•μ‹μΌλ΅ μµμΆ… μ”μ•½μ„ μ‘μ„±ν•΄μ£Όμ„Έμ”:",
            "1. ν•µμ‹¬ ν›„ν μ”μΈ μ„¤λ… (2-3λ¬Έμ¥)",
            "2. κµ¬λ§¤ μ „ μ²΄ν¬ν¬μΈνΈ (3-5κ° ν•­λ©, κ° 1-2λ¬Έμ¥)",
            "3. ν• μ¤„ μ΅°μ–Έ"
        ])
        
        user_prompt = "\n".join(user_prompt_parts)
        
        return system_prompt, user_prompt
    
    def _get_fallback_summary(self, top_factors: List[tuple], category_name: str, product_name: str) -> str:
        """API μ‹¤ν¨ μ‹ κΈ°λ³Έ μ”μ•½"""
        factors_text = ", ".join([f"{key}" for key, _ in top_factors[:3]])
        
        return f"""π” **{product_name} λ¶„μ„ μ™„λ£**

**μ£Όμ” ν›„ν μ”μΈ**: {factors_text}

μ„ μ”μΈλ“¤μ΄ μ‹¤μ  κµ¬λ§¤μλ“¤μ΄ κ°€μ¥ λ§μ΄ ν›„νν• λ¶€λ¶„μ…λ‹λ‹¤.

**κµ¬λ§¤ μ „ μ²΄ν¬ν¬μΈνΈ**:
1. ν•΄λ‹Ή μ”μΈλ“¤μ΄ λ³ΈμΈμ—κ² μ¤‘μ”ν•μ§€ ν™•μΈν•μ„Έμ”
2. λ‚®μ€ ν‰μ  λ¦¬λ·°μ—μ„ κµ¬μ²΄μ μΈ λ¶λ§ λ‚΄μ©μ„ ν™•μΈν•μ„Έμ”
3. μ μ‚¬ μ ν’κ³Ό λΉ„κµν•΄λ³΄μ„Έμ”

π’΅ **μ΅°μ–Έ**: ν›„ν μ”μΈμ„ λ―Έλ¦¬ μ•κ³  κµ¬λ§¤ν•λ©΄ μ‹¤λ§μ„ μ¤„μΌ μ μμµλ‹λ‹¤!
"""
