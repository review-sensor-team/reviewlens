"""Review API Router - Clean Architecture Version (Phase 4)

ë¦¬ë·° ìˆ˜ì§‘ ë° ë¶„ì„ API
"""
import logging
import random
from typing import Optional
from pathlib import Path
import pandas as pd
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel

from ...services.review_service import ReviewService
from ...core.settings import settings
from ...infra.observability.metrics import (
    dialogue_turns_total, 
    track_errors, 
    user_journey_stage_total,
    dialogue_completions_total
)
from ...adapters.persistence.reg.store import load_csvs, parse_factors
from ...usecases.dialogue.session import DialogueSession

logger = logging.getLogger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter(prefix="/api/v2/reviews", tags=["reviews"])

# Service ì¸ìŠ¤í„´ìŠ¤
_review_service: Optional[ReviewService] = None

# ì„¸ì…˜ ìºì‹œ (ë©”ëª¨ë¦¬)
_session_cache: dict = {}  # {session_id: {scored_df, factors, category, product_name}}

# ê³µí†µ ìƒìˆ˜ import
from ...usecases.dialogue.constants import CATEGORY_FALLBACK_QUESTIONS, DEFAULT_FALLBACK_QUESTIONS


def get_data_dir() -> Path:
    """ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ ë°˜í™˜"""
    return Path(__file__).resolve().parent.parent.parent.parent / "data"


def get_review_service() -> ReviewService:
    """ReviewService ì˜ì¡´ì„±"""
    global _review_service
    if _review_service is None:
        _review_service = ReviewService(data_dir=get_data_dir())
    return _review_service


# === Request/Response Models ===

class CollectReviewsRequest(BaseModel):
    """ë¦¬ë·° ìˆ˜ì§‘ ìš”ì²­"""
    product_id: str
    vendor: str = "smartstore"
    max_reviews: int = 100


class CollectReviewsResponse(BaseModel):
    """ë¦¬ë·° ìˆ˜ì§‘ ì‘ë‹µ"""
    product_id: str
    vendor: str
    review_count: int
    message: str


class AnalyzeReviewsRequest(BaseModel):
    """ë¦¬ë·° ë¶„ì„ ìš”ì²­"""
    product_id: str
    category: str
    top_k: int = 3


class AnalyzeReviewsResponse(BaseModel):
    """ë¦¬ë·° ë¶„ì„ ì‘ë‹µ"""
    product_id: str
    review_count: int
    factor_count: int
    top_factors: list[tuple[str, float]]


class AnswerQuestionRequest(BaseModel):
    """ì§ˆë¬¸ ë‹µë³€ ìš”ì²­"""
    answer: str
    question_id: Optional[str] = None
    factor_key: Optional[str] = None


class RateResponseRequest(BaseModel):
    """LLM ì‘ë‹µ í‰ê°€ ìš”ì²­"""
    response_file: str  # llm_response_default_20260118_123456.json
    rating: int  # 1-5 ë³„ì 
    strategy: Optional[str] = None  # ë‹¤ì¤‘ ì „ëµì¸ ê²½ìš° ì–´ë–¤ ì „ëµì¸ì§€
    feedback: Optional[str] = None  # ì„ íƒì  í”¼ë“œë°±


class RateResponseResponse(BaseModel):
    """LLM ì‘ë‹µ í‰ê°€ ì‘ë‹µ"""
    success: bool
    message: str
    response_file: str
    rating: int


# === Helper Functions ===

def _check_convergence(session_data: dict, min_turns: int = 3) -> bool:
    """ìˆ˜ë ´ ì¡°ê±´ ì²´í¬
    
    Args:
        session_data: ì„¸ì…˜ ë°ì´í„°
        min_turns: ìµœì†Œ ì§ˆë¬¸ ë‹µë³€ íšŸìˆ˜
        
    Returns:
        bool: ìˆ˜ë ´ ì—¬ë¶€
    """
    turn_count = len(session_data.get("question_history", []))
    fallback_count = sum(1 for q in session_data.get("question_history", []) if q.get("is_fallback"))
    
    is_converged = (turn_count >= min_turns) or (fallback_count >= 1)
    logger.info(f"ìˆ˜ë ´ ì²´í¬: turn_count={turn_count}, fallback_count={fallback_count}, is_converged={is_converged}")
    
    return is_converged


def _get_current_factor_next_question(
    questions_df,
    current_factor_key: str,
    current_factor_id: int,
    asked_ids: set,
    asked_texts: set
) -> Optional[dict]:
    """í˜„ì¬ factorì˜ ë‹¤ìŒ ì§ˆë¬¸ ì°¾ê¸°
    
    Args:
        questions_df: ì§ˆë¬¸ DataFrame
        current_factor_key: í˜„ì¬ factor key
        current_factor_id: í˜„ì¬ factor ID
        asked_ids: ì´ë¯¸ ë¬¼ì–´ë³¸ ì§ˆë¬¸ ID ì§‘í•©
        asked_texts: ì´ë¯¸ ë¬¼ì–´ë³¸ ì§ˆë¬¸ í…ìŠ¤íŠ¸ ì§‘í•©
        
    Returns:
        dict: ë‹¤ìŒ ì§ˆë¬¸ ì •ë³´ ë˜ëŠ” None
    """
    # factor_idë¡œ ì •í™•íˆ ë§¤ì¹­ë˜ëŠ” ì§ˆë¬¸ë§Œ ì°¾ê¸°
    all_questions = questions_df[questions_df['factor_id'] == current_factor_id]
    logger.info(f"Factor '{current_factor_key}' (factor_id={current_factor_id}) ì „ì²´ ì§ˆë¬¸: {len(all_questions)}ê°œ")
    
    # ì•„ì§ ë¬»ì§€ ì•Šì€ ì§ˆë¬¸ í•„í„°ë§
    related_questions = all_questions[
        (~all_questions['question_id'].isin(asked_ids)) &
        (~all_questions['question_text'].isin(asked_texts))
    ]
    
    logger.info(f"ì•„ì§ ë¬»ì§€ ì•Šì€ ì§ˆë¬¸: {len(related_questions)}ê°œ")
    
    if len(related_questions) > 0:
        next_q = related_questions.iloc[0]
        question = {
            "question_id": next_q['question_id'],
            "question_text": next_q['question_text'],
            "answer_type": next_q['answer_type'],
            "choices": next_q['choices'].split('|') if next_q.get('choices') else [],
            "next_factor_hint": next_q.get('next_factor_hint', ''),
            "factor_key": current_factor_key
        }
        logger.info(f"í˜„ì¬ factor '{current_factor_key}'ì˜ ë‹¤ìŒ ì§ˆë¬¸: question_id={next_q['question_id']}")
        return question
    
    return None


def _filter_unasked_questions(questions_df, asked_ids: set, asked_texts: set):
    """ì•„ì§ ë¬»ì§€ ì•Šì€ ì§ˆë¬¸ í•„í„°ë§"""
    return questions_df[
        (~questions_df['question_id'].isin(asked_ids)) &
        (~questions_df['question_text'].isin(asked_texts))
    ]

def _build_question_dict(question_row, factor_key: str) -> dict:
    """ì§ˆë¬¸ í–‰ì—ì„œ ì§ˆë¬¸ ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
    return {
        "question_id": question_row['question_id'],
        "question_text": question_row['question_text'],
        "answer_type": question_row['answer_type'],
        "choices": question_row['choices'].split('|') if question_row.get('choices') else [],
        "next_factor_hint": question_row.get('next_factor_hint', ''),
        "factor_key": factor_key
    }

def _get_next_factor_question(
    questions_df,
    next_factor_key: str,
    asked_ids: set,
    asked_texts: set
) -> Optional[dict]:
    """next_factor_hintë¡œ ë‹¤ìŒ factorì˜ ì§ˆë¬¸ ì°¾ê¸°
    
    Args:
        questions_df: ì§ˆë¬¸ DataFrame
        next_factor_key: ë‹¤ìŒ factor key
        asked_ids: ì´ë¯¸ ë¬¼ì–´ë³¸ ì§ˆë¬¸ ID ì§‘í•©
        asked_texts: ì´ë¯¸ ë¬¼ì–´ë³¸ ì§ˆë¬¸ í…ìŠ¤íŠ¸ ì§‘í•©
        
    Returns:
        dict: ë‹¤ìŒ ì§ˆë¬¸ ì •ë³´ ë˜ëŠ” None
    """
    next_factor_questions = questions_df[questions_df['factor_key'] == next_factor_key]
    
    if len(next_factor_questions) == 0:
        logger.info(f"CSVì—ì„œ next_factor_key '{next_factor_key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return None
    
    next_unasked = _filter_unasked_questions(next_factor_questions, asked_ids, asked_texts)
    next_factor_id = int(next_factor_questions.iloc[0]['factor_id'])
    logger.info(f"ë‹¤ìŒ factor '{next_factor_key}' (factor_id={next_factor_id}) ì§ˆë¬¸: {len(next_factor_questions)}ê°œ, ë¯¸ì§ˆë¬¸: {len(next_unasked)}ê°œ")
    
    if len(next_unasked) > 0:
        next_q = next_unasked.iloc[0]
        question = _build_question_dict(next_q, next_factor_key)
        logger.info(f"ë‹¤ìŒ factor '{next_factor_key}'ë¡œ ì´ë™: question_id={next_q['question_id']}")
        return question
    
    logger.info(f"ë‹¤ìŒ factor '{next_factor_key}'ì˜ ì§ˆë¬¸ë„ ëª¨ë‘ ì†Œì§„ë¨")
    return None


def _get_fallback_question(session_data: dict, current_factor_key: str) -> Optional[dict]:
    """Fallback ì§ˆë¬¸ ì„ íƒ
    
    Args:
        session_data: ì„¸ì…˜ ë°ì´í„°
        current_factor_key: í˜„ì¬ factor key
        
    Returns:
        dict: Fallback ì§ˆë¬¸ ì •ë³´ ë˜ëŠ” None
    """
    category = session_data.get("category", "")
    fallback_questions = CATEGORY_FALLBACK_QUESTIONS.get(category, DEFAULT_FALLBACK_QUESTIONS)
    
    # ì´ë¯¸ ë¬¼ì–´ë³¸ fallback ì§ˆë¬¸ ì¶”ì 
    if "asked_fallback_questions" not in session_data:
        session_data["asked_fallback_questions"] = []
    
    asked_fallbacks = set(session_data["asked_fallback_questions"])
    unasked_fallbacks = [q for q in fallback_questions if q not in asked_fallbacks]
    
    if unasked_fallbacks:
        fb_q = random.choice(unasked_fallbacks)
        question = {
            "question_id": None,
            "question_text": fb_q,
            "answer_type": "no_choice",
            "choices": [],
            "next_factor_hint": "",
            "factor_key": current_factor_key,
            "is_fallback": True
        }
        session_data["asked_fallback_questions"].append(fb_q)
        logger.info(f"Fallback ì§ˆë¬¸ ëœë¤ ì„ íƒ: {fb_q}")
        return question
    
    return None


def _find_next_question(session_data: dict, questions_df, current_factor_key: str, current_factor: any) -> Optional[dict]:
    """ë‹¤ìŒ ì§ˆë¬¸ ì°¾ê¸° (ì „ì²´ ë¡œì§)
    
    Args:
        session_data: ì„¸ì…˜ ë°ì´í„°
        questions_df: ì§ˆë¬¸ DataFrame
        current_factor_key: í˜„ì¬ factor key
        current_factor: í˜„ì¬ factor ê°ì²´
        
    Returns:
        dict: ë‹¤ìŒ ì§ˆë¬¸ ì •ë³´ ë˜ëŠ” None
    """
    asked_ids = {q["question_id"] for q in session_data["question_history"] if q.get("question_id")}
    asked_texts = {q["question_text"] for q in session_data["question_history"] if q.get("question_text")}
    
    # 1. í˜„ì¬ factorì˜ ë‹¤ìŒ ì§ˆë¬¸ í™•ì¸
    next_question = _get_current_factor_next_question(
        questions_df, current_factor_key, current_factor.factor_id,
        asked_ids, asked_texts
    )
    
    if next_question:
        return next_question
    
    # 2. í˜„ì¬ factor ì†Œì§„ - next_factor_hint í™•ì¸
    logger.info(f"Factor '{current_factor_key}' ì§ˆë¬¸ ì†Œì§„ - next_factor_hint í™•ì¸")
    
    prev_question = session_data.get("current_question", {})
    next_factor_key = prev_question.get('next_factor_hint', '')
    logger.info(f"ë°©ê¸ˆ ë‹µë³€í•œ ì§ˆë¬¸ì˜ next_factor_hint: '{next_factor_key}'")
    
    if next_factor_key:
        next_question = _get_next_factor_question(
            questions_df, next_factor_key,
            asked_ids, asked_texts
        )
        
        if next_question:
            return next_question
    
    # 3. fallback ì§ˆë¬¸ ì‚¬ìš©
    logger.info(f"ë‹¤ìŒ factor ì—†ìŒ ë˜ëŠ” ì§ˆë¬¸ ì†Œì§„ - fallback ì§ˆë¬¸ ì‚¬ìš©")
    return _get_fallback_question(session_data, current_factor_key)


# ============================================================================
# Helper Functions for get_factor_reviews
# ============================================================================

def _extract_matched_sentences(text: str, anchor_terms: list, max_length: int = 100) -> tuple[list, list]:
    """anchor_termì´ í¬í•¨ëœ ë¬¸ì¥ ì¶”ì¶œ
    
    Args:
        text: ë¦¬ë·° í…ìŠ¤íŠ¸
        anchor_terms: ë§¤ì¹­í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        max_length: ë¬¸ì¥ ìµœëŒ€ ê¸¸ì´
        
    Returns:
        (matched_sentences, matched_terms) íŠœí”Œ
    """
    sentences = text.split('.')
    matched_sentences = []
    matched_terms = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence or len(sentence) < 10:
            continue
            
        for term in anchor_terms:
            if term in sentence:
                # í‚¤ì›Œë“œ ì•ë’¤ ì ë‹¹íˆ ìë¥´ê¸°
                if len(sentence) > max_length:
                    term_pos = sentence.find(term)
                    start = max(0, term_pos - 30)
                    end = min(len(sentence), term_pos + len(term) + 50)
                    sentence = '...' + sentence[start:end] + '...'
                
                matched_sentences.append(sentence)
                if term not in matched_terms:
                    matched_terms.append(term)
                break
    
    return matched_sentences, matched_terms


def _build_review_samples(matched_df, target_factor, limit: int = 5) -> list:
    """ë§¤ì¹­ëœ ë¦¬ë·°ì—ì„œ ìƒ˜í”Œ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
    
    Args:
        matched_df: ë§¤ì¹­ëœ ë¦¬ë·° DataFrame
        target_factor: Factor ê°ì²´
        limit: ìµœëŒ€ ë¦¬ë·° ê°œìˆ˜
        
    Returns:
        ë¦¬ë·° ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸
    """
    reviews = []
    seen_texts = set()
    
    for _, row in matched_df.iterrows():
        text = row['text']
        
        # ì¤‘ë³µ ì²´í¬
        if text in seen_texts:
            continue
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ë¬¸ì¥ ì¶”ì¶œ
        matched_sentences, matched_terms = _extract_matched_sentences(
            text, 
            target_factor.anchor_terms
        )
        
        # ë§¤ì¹­ëœ ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not matched_sentences:
            continue
        
        reviews.append({
            "rating": int(row.get('rating', 0)),
            "sentences": matched_sentences[:3],  # ìµœëŒ€ 3ë¬¸ì¥
            "matched_terms": matched_terms
        })
        
        seen_texts.add(text)
        
        if len(reviews) >= limit:
            break
    
    return reviews


def _load_factor_questions(factor_key: str) -> list:
    """Factorì— í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸ ë¡œë“œ
    
    Args:
        factor_key: Factor key
        
    Returns:
        ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
    """
    _, _, questions_df = load_csvs(get_data_dir())
    
    related_questions = questions_df[
        questions_df['factor_key'] == factor_key
    ].to_dict('records')
    
    return [{
        "question_id": q['question_id'],
        "question_text": q['question_text'],
        "answer_type": q['answer_type'],
        "choices": q['choices'].split('|') if q.get('choices') else [],
        "next_factor_hint": q.get('next_factor_hint', '')
    } for q in related_questions]


def _calculate_term_stats(reviews: list, anchor_terms: dict) -> dict:
    """ë§¤ì¹­ëœ ìš©ì–´ í†µê³„ ê³„ì‚°"""
    term_stats = {}
    for term in anchor_terms:
        count = sum(1 for r in reviews if term in r.get('matched_terms', []))
        if count > 0:
            term_stats[term] = count
    return term_stats

def _create_review_summary_message(factor_display_name: str, term_stats: dict) -> str:
    """ë¦¬ë·° ìš”ì•½ ë©”ì‹œì§€ ìƒì„±"""
    term_summary = ", ".join([
        f"'{term}' {count}ê±´" 
        for term, count in sorted(term_stats.items(), key=lambda x: -x[1])
    ])
    return f'"{factor_display_name}"ê³¼ ê´€ë ¨ëœ ë¦¬ë·°ë¥¼ {term_summary}ì„ ì°¾ì•˜ì–´ìš”.'

def _add_to_dialogue_history(session_data: dict, user_message: str, assistant_message: str):
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€"""
    if "dialogue_history" not in session_data:
        session_data["dialogue_history"] = []
    
    session_data["dialogue_history"].append({"role": "user", "message": user_message})
    session_data["dialogue_history"].append({"role": "assistant", "message": assistant_message})

def _update_dialogue_with_factor_selection(session_id: str, target_factor, reviews: list, anchor_terms: dict, questions: list):
    """Factor ì„ íƒ ì‹œ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    
    Args:
        session_id: ì„¸ì…˜ ID
        target_factor: Factor ê°ì²´
        reviews: ë¦¬ë·° ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸
        anchor_terms: anchor_term ì¹´ìš´íŠ¸ ë”•ì…”ë„ˆë¦¬
        questions: ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
    """
    global _session_cache
    
    if session_id not in _session_cache:
        return
    
    session_data = _session_cache[session_id]
    
    # ë§¤ì¹­ëœ ìš©ì–´ í†µê³„ ë° ìš”ì•½ ë©”ì‹œì§€ ìƒì„±
    term_stats = _calculate_term_stats(reviews, anchor_terms)
    review_summary = _create_review_summary_message(target_factor.display_name, term_stats)
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    _add_to_dialogue_history(session_data, target_factor.display_name, review_summary)
    
    # ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ current_questionì— ì €ì¥
    if questions:
        session_data["current_question"] = questions[0]
        logger.info(f"current_question ì €ì¥: {questions[0].get('question_text', '')[:50]}")
    
    logger.info(f"ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸: {target_factor.display_name} ì„ íƒ")


# ============================================================================
# Helper Functions for analyze_product
# ============================================================================

def _load_product_info(product_name: str) -> tuple:
    """Factor CSVì—ì„œ ìƒí’ˆ ì •ë³´ ë¡œë“œ
    
    Args:
        product_name: ìƒí’ˆëª…
        
    Returns:
        (category, category_name) íŠœí”Œ
        
    Raises:
        HTTPException: íŒŒì¼ ì—†ìŒ ë˜ëŠ” ìƒí’ˆ ì—†ìŒ
    """
    factor_csv_path = get_data_dir() / "factor" / "reg_factor_v4.csv"
    if not factor_csv_path.exists():
        raise HTTPException(status_code=404, detail="Factor CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    df = pd.read_csv(factor_csv_path)
    
    product_rows = df[df['product_name'] == product_name]
    if product_rows.empty:
        raise HTTPException(status_code=404, detail=f"'{product_name}' ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    return product_rows.iloc[0]['category'], product_rows.iloc[0]['category_name']


def _load_review_data(category: str, service: ReviewService):
    """ë¦¬ë·° íŒŒì¼ ë¡œë“œ ë° ì •ê·œí™”
    
    Args:
        category: ì¹´í…Œê³ ë¦¬
        service: ReviewService ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        ì •ê·œí™”ëœ ë¦¬ë·° DataFrame
        
    Raises:
        HTTPException: ë¦¬ë·° íŒŒì¼ ì—†ìŒ
    """

    # ğŸ“Š ì‚¬ìš©ì ì—¬ì •: ë¦¬ë·° ìˆ˜ì§‘ ë‹¨ê³„ ì§„ì…
    user_journey_stage_total.labels(
        stage="review_collection",
        action="enter",
        category=category
    ).inc()

    loader = service._get_review_loader()
    review_df = None
    vendor = "smartstore"
    
    if loader:
        review_df = loader.load_by_category(category=category, latest=True)
        if review_df is not None:
            logger.info(f"ë¦¬ë·° ë¡œë“œ ì„±ê³µ: category={category} ({len(review_df)}ê±´)")
    
    if review_df is None or len(review_df) == 0:
        raise HTTPException(
            status_code=404,
            detail=f"ì¹´í…Œê³ ë¦¬ '{category}'ì˜ ë¦¬ë·° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        )
    
    return service.normalize_reviews(review_df, vendor=vendor)


def _extract_suggested_factors(top_factors: list, factors: list) -> list:
    """Top factorsì—ì„œ API ì‘ë‹µìš© suggested factors ì¶”ì¶œ
    
    Args:
        top_factors: [(factor_key, score), ...] ë¦¬ìŠ¤íŠ¸
        factors: Factor ê°ì²´ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        Suggested factors ë¦¬ìŠ¤íŠ¸ (dict)
    """
    factor_map = {f.factor_key: f for f in factors}
    return [
        {
            "factor_id": factor_map[factor_key].factor_id,
            "factor_key": factor_key,
            "display_name": factor_map[factor_key].display_name
        }
        for factor_key, score in top_factors
    ]

def _create_initial_dialogue(product_name: str, review_count: int, suggested_factors: list) -> list:
    """ì´ˆê¸° ëŒ€í™” ë‚´ì—­ ìƒì„±
    
    Args:
        product_name: ìƒí’ˆëª…
        review_count: ë¦¬ë·° ê°œìˆ˜
        suggested_factors: Suggested factors ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ì´ˆê¸° ëŒ€í™” ë‚´ì—­ (role, message í¬í•¨)
    """
    factor_list_text = "\n".join([
        f"- {f['display_name']}"
        for f in suggested_factors
    ])
    
    analysis_message = f"{product_name} {review_count}ê±´ì˜ ë¦¬ë·°ì—ì„œ í›„íšŒ í¬ì¸íŠ¸ë¥¼ ë¶„ì„í–ˆì–´ìš”. ì•„ë˜ í•­ëª© ì¤‘ ê¶ê¸ˆí•œ ê±¸ ì„ íƒí•´ì£¼ì„¸ìš”!"
    
    return [
        {
            "role": "assistant",
            "message": f"{analysis_message}\n{factor_list_text}"
        }
    ]

def _cache_session(session_id: str, session_cache_data: dict) -> None:
    """ì„¸ì…˜ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
    
    Args:
        session_id: ì„¸ì…˜ ID
        session_cache_data: ìºì‹±í•  ì„¸ì…˜ ë°ì´í„°
    """
    global _session_cache
    _session_cache[session_id] = session_cache_data
    logger.info(f"ìƒí’ˆ ë¶„ì„ ì™„ë£Œ: {session_cache_data['product_name']} - ì„¸ì…˜ ìºì‹± ì™„ë£Œ")

def _create_session_data(session_id: str, product_name: str, category: str, category_name: str, 
                         normalized_df, analysis: dict, factors: list) -> dict:
    """ì„¸ì…˜ ë°ì´í„° ìƒì„± ë° ìºì‹±
    
    Args:
        session_id: ì„¸ì…˜ ID
        product_name: ìƒí’ˆëª…
        category: ì¹´í…Œê³ ë¦¬
        category_name: ì¹´í…Œê³ ë¦¬ í‘œì‹œëª…
        normalized_df: ì •ê·œí™”ëœ ë¦¬ë·° DataFrame
        analysis: ë¶„ì„ ê²°ê³¼
        factors: Factor ë¦¬ìŠ¤íŠ¸
        
    Returns:
        API ì‘ë‹µìš© ë”•ì…”ë„ˆë¦¬
    """
    suggested_factors = _extract_suggested_factors(analysis["top_factors"], factors)
    initial_dialogue = _create_initial_dialogue(product_name, len(normalized_df), suggested_factors)
    
    session_cache_data = {
        "scored_df": analysis["scored_reviews_df"],
        "normalized_df": normalized_df,
        "factors": factors,
        "top_factors": analysis["top_factors"],
        "category": category,
        "product_name": product_name,
        "dialogue_history": initial_dialogue
    }
    
    _cache_session(session_id, session_cache_data)
    
    return {
        "session_id": session_id,
        "suggested_factors": suggested_factors,
        "product_name": product_name,
        "total_count": len(normalized_df),
        "category": category,
        "category_name": category_name
    }


# === API Endpoints ===

@router.post("/collect", response_model=CollectReviewsResponse)
@track_errors(error_type='api_error', component='collect_reviews')
async def collect_reviews(
    request: CollectReviewsRequest,
    review_service: ReviewService = Depends(get_review_service)
):
    """ë¦¬ë·° ìˆ˜ì§‘
    
    Service ë ˆì´ì–´ì˜ collect_reviews()ë¥¼ í˜¸ì¶œí•˜ì—¬ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    """
    logger.info(f"ë¦¬ë·° ìˆ˜ì§‘ ìš”ì²­: product={request.product_id}, vendor={request.vendor}")
    
    try:
        # Service ë ˆì´ì–´ í˜¸ì¶œ
        result = review_service.collect_reviews(
            product_id=request.product_id,
            vendor=request.vendor,
            max_reviews=request.max_reviews
        )
        
        logger.info(f"ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ: {result['review_count']}ê±´")
        
        return CollectReviewsResponse(
            product_id=result["product_id"],
            vendor=result["vendor"],
            review_count=result["review_count"],
            message=f"{result['review_count']}ê±´ì˜ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤."
        )
    except Exception as e:
        logger.error(f"ë¦¬ë·° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ë¦¬ë·° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")


@router.post("/analyze", response_model=AnalyzeReviewsResponse)
@track_errors(error_type='api_error', component='analyze_reviews')
async def analyze_reviews(
    request: AnalyzeReviewsRequest,
    review_service: ReviewService = Depends(get_review_service)
):
    """ë¦¬ë·° ë¶„ì„
    
    Service ë ˆì´ì–´ë¥¼ í˜¸ì¶œí•˜ì—¬ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ê³  top factorsë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    logger.info(f"ë¦¬ë·° ë¶„ì„ ìš”ì²­: product={request.product_id}, category={request.category}")
    
    try:
        # 1. ë¦¬ë·° ìˆ˜ì§‘
        collect_result = review_service.collect_reviews(
            product_id=request.product_id,
            vendor="smartstore"
        )
        reviews_df = collect_result["reviews_df"]
        
        # 2. ì •ê·œí™”
        normalized_df = review_service.normalize_reviews(reviews_df, vendor="smartstore")
        
        # 3. Factors ë¡œë“œ
        data_dir = get_data_dir()
        _, factors_df, _ = load_csvs(data_dir)
        all_factors = parse_factors(factors_df)
        factors = [f for f in all_factors if f.category == request.category]
        
        # 4. ë¶„ì„
        analysis = review_service.analyze_reviews(
            reviews_df=normalized_df,
            factors=factors,
            top_k=request.top_k
        )
        
        logger.info(f"ë¦¬ë·° ë¶„ì„ ì™„ë£Œ: {len(analysis['top_factors'])}ê°œ top factors")
        
        return AnalyzeReviewsResponse(
            product_id=request.product_id,
            review_count=analysis["review_count"],
            factor_count=len(analysis["factor_scores"]),
            top_factors=analysis["top_factors"]
        )
    except Exception as e:
        logger.error(f"ë¦¬ë·° ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ë¦¬ë·° ë¶„ì„ ì‹¤íŒ¨: {str(e)}")


@router.get("/products")
async def get_available_products(
    service: ReviewService = Depends(get_review_service)
):
    # ğŸ“Š ì‚¬ìš©ì ì—¬ì •: ìƒí’ˆ ì„ íƒ ë‹¨ê³„ ì§„ì…
    user_journey_stage_total.labels(
        stage="product_selection",
        action="enter",
        category="unknown"
    ).inc()

    """ì‚¬ìš© ê°€ëŠ¥í•œ ìƒí’ˆ ëª©ë¡ ì¡°íšŒ
    
    USE_PRODUCT_SELECTION=Trueì¼ ë•Œ ì‚¬ìš©
    
    Returns:
        { products: [{ product_id, product_name, category, review_count }] }
    """
    try:
        logger.info("ìƒí’ˆ ëª©ë¡ ì¡°íšŒ ìš”ì²­")
        products = service.get_available_products()
        
        return {
            "success": True,
            "count": len(products),
            "products": products
        }
    except Exception as e:
        logger.error(f"ìƒí’ˆ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ìƒí’ˆ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@router.get("/config")
async def get_app_config():
    """ì•± ì„¤ì • ì¡°íšŒ
    
    Returns:
        - use_product_selection: ìƒí’ˆ ì„ íƒ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
        - mode: 'product_selection' ë˜ëŠ” 'url_input'
        - strategy_names: ì „ëµ ì´ë¦„ í•œê¸€ ë§¤í•‘
    """
    return {
        "success": True,
        "use_product_selection": settings.USE_PRODUCT_SELECTION,
        "mode": "product_selection" if settings.USE_PRODUCT_SELECTION else "url_input",
        "strategy_names": settings.STRATEGY_KOREAN_NAMES
    }


@router.post("/analyze-product")
@track_errors(error_type='api_error', component='analyze_product')
async def analyze_product(
    product_name: str,
    service: ReviewService = Depends(get_review_service)
):
    """ìƒí’ˆëª…ìœ¼ë¡œ ë¦¬ë·° ë¶„ì„ ì‹œì‘
    
    Factor CSVì—ì„œ ìƒí’ˆì„ ì°¾ê³ , í•´ë‹¹ ìƒí’ˆì˜ ë¦¬ë·° íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        product_name: ìƒí’ˆëª… (ì˜ˆ: "ë„¤ìŠ¤í”„ë ˆì†Œ ë²„ì¸„ì˜¤í”ŒëŸ¬ìŠ¤")
        
    Returns:
        {
            "session_id": str,
            "suggested_factors": List[str],
            "product_name": str,
            "total_count": int,
            "category": str,
            "category_name": str
        }
    """
    try:
        logger.info(f"ìƒí’ˆ ë¶„ì„ ìš”ì²­: {product_name}")
        
        # 1. ìƒí’ˆ ì •ë³´ ë¡œë“œ (helper í•¨ìˆ˜)
        category, category_name = _load_product_info(product_name)
        
        # 2. ë¦¬ë·° ë°ì´í„° ë¡œë“œ ë° ì •ê·œí™” (helper í•¨ìˆ˜)
        normalized_df = _load_review_data(category, service)
        
        # 3. Factor ë¡œë“œ (í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë§Œ)
        _, factors_df, _ = load_csvs(get_data_dir())
        all_factors = parse_factors(factors_df)
        factors = [f for f in all_factors if f.category == category]
        
        if not factors:
            raise HTTPException(
                status_code=404,
                detail=f"'{category_name}' ì¹´í…Œê³ ë¦¬ì˜ Factorë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            )
        
        # 4. ë¦¬ë·° ë¶„ì„
        analysis = service.analyze_reviews(
            reviews_df=normalized_df,
            factors=factors,
            top_k=5,
            save_results=False,
            category=category,
            product_id=product_name
        )
        
        # ğŸ“Š ì‚¬ìš©ì ì—¬ì •: ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ & ëŒ€í™” ì‹œì‘ ì§„ì…
        user_journey_stage_total.labels(
            stage="review_collection",
            action="complete",
            category=category
        ).inc()
        user_journey_stage_total.labels(
            stage="dialogue_start",
            action="enter",
            category=category
        ).inc()
        
        # 5. ì„¸ì…˜ ë°ì´í„° ìƒì„± ë° ìºì‹± (helper í•¨ìˆ˜)
        session_id = f"session-{category}-{hash(product_name) % 100000}"
        return _create_session_data(
            session_id, product_name, category, category_name,
            normalized_df, analysis, factors
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìƒí’ˆ ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ìƒí’ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@router.get("/factor-reviews/{session_id}/{factor_key}")
@track_errors(error_type='api_error', component='get_factor_reviews')
async def get_factor_reviews(
    session_id: str,
    factor_key: str,
    limit: int = 5,
    service: ReviewService = Depends(get_review_service)
):
    """Factorë³„ ê´€ë ¨ ë¦¬ë·° ë° ì§ˆë¬¸ ì¡°íšŒ
    
    Args:
        session_id: ì„¸ì…˜ ID (analyze-product ì‘ë‹µì—ì„œ ë°›ì€ ê°’)
        factor_key: Factor key (ì˜ˆ: noise_loud, crema_quality)
        limit: ë¦¬ë·° ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)
        
    Returns:
        {
            "factor_key": str,
            "display_name": str,
            "total_count": int,
            "anchor_terms": dict,  # {term: count}
            "reviews": [...],
            "questions": [...]
        }
    """
    try:
        logger.info(f"Factor ë¦¬ë·° ì¡°íšŒ: session_id={session_id}, factor_key={factor_key}, limit={limit}")
        
        # 1. ì„¸ì…˜ ë°ì´í„° ê²€ì¦
        global _session_cache
        if session_id not in _session_cache:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        session_data = _session_cache[session_id]
        scored_df = session_data.get("scored_df")
        factors = session_data.get("factors")
        
        if scored_df is None or factors is None:
            raise HTTPException(status_code=500, detail="ì„¸ì…˜ ë°ì´í„°ê°€ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤")
        
        # 2. Factor ì°¾ê¸°
        target_factor = next((f for f in factors if f.factor_key == factor_key), None)
        if not target_factor:
            raise HTTPException(status_code=404, detail=f"Factor '{factor_key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # 3. ë§¤ì¹­ëœ ë¦¬ë·° í•„í„°ë§
        score_col = f"score_{factor_key}"
        if score_col not in scored_df.columns:
            raise HTTPException(status_code=404, detail=f"Score ì»¬ëŸ¼ '{score_col}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        matched_df = scored_df[scored_df[score_col] > 0].copy()
        matched_df = matched_df.sort_values(score_col, ascending=False)
        logger.info(f"ë§¤ì¹­ëœ ë¦¬ë·°: {len(matched_df)}ê±´")
        
        # 4. anchor_termë³„ ì¹´ìš´íŠ¸
        anchor_terms = {}
        for term in target_factor.anchor_terms:
            count = matched_df['text'].str.contains(term, case=False, na=False).sum()
            if count > 0:
                anchor_terms[term] = int(count)
        
        # 5. ë¦¬ë·° ìƒ˜í”Œ ìƒì„± (helper í•¨ìˆ˜ ì‚¬ìš©)
        reviews = _build_review_samples(matched_df, target_factor, limit)
        
        # 6. ì§ˆë¬¸ ë¡œë“œ (helper í•¨ìˆ˜ ì‚¬ìš©)
        questions = _load_factor_questions(factor_key)
        
        logger.info(f"ë¦¬ë·° ì¡°íšŒ ì™„ë£Œ: {len(reviews)}ê±´, ì§ˆë¬¸ {len(questions)}ê°œ")
        
        # 7. ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (helper í•¨ìˆ˜ ì‚¬ìš©)
        _update_dialogue_with_factor_selection(session_id, target_factor, reviews, anchor_terms, questions)
        
        return {
            "factor_key": factor_key,
            "display_name": target_factor.display_name,
            "total_count": len(matched_df),
            "anchor_terms": anchor_terms,
            "reviews": reviews,
            "questions": questions
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Factor ë¦¬ë·° ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ë¦¬ë·° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@router.post("/answer-question/{session_id}")
@track_errors(error_type='api_error', component='answer_question')
async def answer_question(
    session_id: str,
    request: AnswerQuestionRequest,
    service: ReviewService = Depends(get_review_service)
):
    """ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ ë˜ëŠ” ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
    
    Args:
        session_id: ì„¸ì…˜ ID
        request: ì§ˆë¬¸ ë‹µë³€ ìš”ì²­ (answer, question_id, factor_key)
        answer: ì‚¬ìš©ì ë‹µë³€
        question_id: ì§ˆë¬¸ ID (ì„ íƒ)
        factor_key: í˜„ì¬ factor_key (ì„ íƒ)
        
    Returns:
        {
            "next_question": {
                "question_id": str,
                "question_text": str,
                "answer_type": str,
                "choices": [str],
                "next_factor_hint": str
            },
            "is_converged": bool,  # ìˆ˜ë ´ ì¡°ê±´ ë‹¬ì„± ì—¬ë¶€
            "analysis": {...}  # is_converged=trueì¼ ë•Œë§Œ ì œê³µ
        }
    """
    try:
        print(f"[DEBUG] ì§ˆë¬¸ ë‹µë³€ ì²˜ë¦¬: session_id={session_id}, answer={request.answer}, question_id={request.question_id}, factor_key={request.factor_key}")
        logger.info(f"ì§ˆë¬¸ ë‹µë³€ ì²˜ë¦¬: session_id={session_id}, answer={request.answer}, question_id={request.question_id}, factor_key={request.factor_key}")
        
        # 1. ì„¸ì…˜ ìºì‹œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        global _session_cache
        if session_id not in _session_cache:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        session_data = _session_cache[session_id]
        
        # 2. ì§ˆë¬¸ íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ì„¸ì…˜ì— ì €ì¥)
        if "question_history" not in session_data:
            session_data["question_history"] = []
        
        # ì´ì „ ì§ˆë¬¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì„¸ì…˜ì— ì €ì¥ëœ current_question ì‚¬ìš©)
        prev_question = session_data.get("current_question", {})
        question_text = prev_question.get("question_text", "")
        
        session_data["question_history"].append({
            "question_id": request.question_id,
            "question_text": question_text,  # ì§ˆë¬¸ í…ìŠ¤íŠ¸ë„ ì €ì¥
            "answer": request.answer,
            "factor_key": request.factor_key
        })
        
        # dialogue_historyì—ë„ ì¶”ê°€
        if "dialogue_history" not in session_data:
            session_data["dialogue_history"] = []
        
        session_data["dialogue_history"].append({"role": "assistant", "message": question_text})
        session_data["dialogue_history"].append({"role": "user", "message": request.answer})
        
        turn_count = len(session_data["question_history"])
        logger.info(f"ì§ˆë¬¸ íˆìŠ¤í† ë¦¬: {turn_count}í„´, ëŒ€í™” íˆìŠ¤í† ë¦¬: {len(session_data['dialogue_history'])}ê°œ")
        
        # ë©”íŠ¸ë¦­ ê¸°ë¡: ëŒ€í™” í„´ ì¦ê°€
        category = session_data.get("category", "unknown")
        dialogue_turns_total.labels(category=category).inc()
        
        # ğŸ“Š ì‚¬ìš©ì ì—¬ì •: ëŒ€í™” ì§„í–‰ ì¤‘
        user_journey_stage_total.labels(
            stage="dialogue_active",
            action="enter",
            category=category
        ).inc()
        
        # 3. ìˆ˜ë ´ ì¡°ê±´ ì²´í¬
        is_converged = _check_convergence(session_data, min_turns=3)
        
        # 4. ìˆ˜ë ´ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë‹¤ìŒ ì§ˆë¬¸ ë¡œë“œ
        if not is_converged:
            _, _, questions_df = load_csvs(get_data_dir())
            
            # factor_key ê²°ì •
            current_factor_key = request.factor_key or (session_data.get("factors", [])[0].factor_key if session_data.get("factors") else None)
            if not current_factor_key:
                raise HTTPException(status_code=400, detail="factor_keyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ì„¸ì…˜ì˜ factor ì¤‘ì—ì„œ í˜„ì¬ factor_keyì— í•´ë‹¹í•˜ëŠ” factor ì°¾ê¸°
            current_factor = next((f for f in session_data.get("factors", []) if f.factor_key == current_factor_key), None)
            if not current_factor:
                raise HTTPException(status_code=400, detail=f"ì„¸ì…˜ì— factor_key '{current_factor_key}'ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # ë‹¤ìŒ ì§ˆë¬¸ ì°¾ê¸° (helper í•¨ìˆ˜ ì‚¬ìš©)
            next_question = _find_next_question(session_data, questions_df, current_factor_key, current_factor)
            
            if next_question:
                # ì„¸ì…˜ì— í˜„ì¬ ì§ˆë¬¸ ì €ì¥
                session_data["current_question"] = next_question
                
                logger.info(f"ë‹¤ìŒ ì§ˆë¬¸: {next_question.get('question_id', 'fallback')}")
                
                return {
                    "next_question": next_question,
                    "related_reviews": [],
                    "review_message": "",
                    "is_converged": False,
                    "turn_count": turn_count
                }
            else:
                # ë” ì´ìƒ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ìˆ˜ë ´ìœ¼ë¡œ ê°„ì£¼
                logger.info(f"ë” ì´ìƒ ì§ˆë¬¸ì´ ì—†ìŒ - ìˆ˜ë ´ ì²˜ë¦¬")
                is_converged = True
        
        # 5. ìˆ˜ë ´ë˜ì—ˆìœ¼ë©´ ë¶„ì„ ê²°ê³¼ ìƒì„± (LLM í˜¸ì¶œ)
        if is_converged:
            logger.info(f"ìˆ˜ë ´ ì¡°ê±´ ë‹¬ì„± - LLM ë¶„ì„ ì‹œì‘")
            
            # DialogueSession ìƒì„± (dialogue_history ì „ë‹¬)
            normalized_df = session_data.get("normalized_df")
            if normalized_df is None:
                # ê¸°ì¡´ ì„¸ì…˜ í˜¸í™˜ì„±: scored_df ì‚¬ìš© (fallback)
                logger.warning("normalized_dfê°€ ì„¸ì…˜ì— ì—†ìŒ - scored_df ì‚¬ìš© (ê¸°ì¡´ ì„¸ì…˜ í˜¸í™˜)")
                normalized_df = session_data.get("scored_df")
            
            dialogue_session = DialogueSession(
                category=session_data.get("category"),
                data_dir=get_data_dir(),
                reviews_df=normalized_df,  # ì›ë³¸ normalized_df ì „ë‹¬ (LLM ë¶„ì„ìš©)
                product_name=session_data.get("product_name", "ì´ ì œí’ˆ")
            )
            
            # ì„¸ì…˜ì˜ dialogue_history ë³µì› (ì´ˆê¸° ì•ˆë‚´ + í‚¤ì›Œë“œ ì„ íƒ + ì§ˆë¬¸-ë‹µë³€ ëª¨ë‘ í¬í•¨)
            dialogue_session.dialogue_history = session_data.get("dialogue_history", [])
            
            dialogue_session.turn_count = len(session_data.get("question_history", []))
            # (ì„¸ì…˜ì— ì €ì¥ëœ top_factors ì‚¬ìš©)
            top_factors = session_data.get("top_factors", [])[:3]  # (factor_key, score) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
            
            # LLM ë¶„ì„ ìƒì„±
            llm_context = dialogue_session._generate_analysis(top_factors)
            
            logger.info(f"LLM ë¶„ì„ ì™„ë£Œ - llm_summary ê¸¸ì´: {len(llm_context.get('llm_summary', ''))}")
            
            # ğŸ“Š ì‚¬ìš©ì ì—¬ì •: ëŒ€í™” ì™„ë£Œ
            user_journey_stage_total.labels(
                stage="dialogue_complete",
                action="complete",
                category=category
            ).inc()
            
            # ğŸ“Š ëŒ€í™” ì„¸ì…˜ ì™„ë£Œ ë©”íŠ¸ë¦­
            dialogue_completions_total.labels(category=category).inc()
            
            return {
                "next_question": None,
                "is_converged": True,
                "turn_count": turn_count,
                "analysis": llm_context  # LLM ë¶„ì„ ê²°ê³¼ ì „ì²´ ë°˜í™˜
            }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì§ˆë¬¸ ë‹µë³€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì§ˆë¬¸ ë‹µë³€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@router.post("/rate-response", response_model=RateResponseResponse)
def rate_llm_response(
    request: RateResponseRequest
) -> RateResponseResponse:
    """LLM ì‘ë‹µ í‰ê°€
    
    ì‚¬ìš©ìê°€ LLM ì‘ë‹µì— ëŒ€í•´ ë³„ì (1-5)ì„ ë§¤ê¸°ë©´,
    í•´ë‹¹ ì‘ë‹µ íŒŒì¼ì— í‰ê°€ ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        request: í‰ê°€ ìš”ì²­
            - response_file: ì‘ë‹µ íŒŒì¼ëª…
            - rating: 1-5 ë³„ì 
            - strategy: (ì˜µì…˜) ì „ëµ ì´ë¦„
            - feedback: (ì˜µì…˜) í…ìŠ¤íŠ¸ í”¼ë“œë°±
    
    Returns:
        í‰ê°€ ê²°ê³¼
    """
    try:
        import json
        from datetime import datetime
        
        # íŒŒì¼ ê²½ë¡œ êµ¬ì„±
        out_dir = Path("out")
        response_path = out_dir / request.response_file
        
        if not response_path.exists():
            raise HTTPException(
                status_code=404,
                detail=f"ì‘ë‹µ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {request.response_file}"
            )
        
        # ë³„ì  ë²”ìœ„ ê²€ì¦
        if not (1 <= request.rating <= 5):
            raise HTTPException(
                status_code=400,
                detail="ë³„ì ì€ 1-5 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤"
            )
        
        # ê¸°ì¡´ íŒŒì¼ ì½ê¸°
        with open(response_path, 'r', encoding='utf-8') as f:
            response_data = json.load(f)
        
        # í‰ê°€ ì •ë³´ ì¶”ê°€
        if "_user_rating" not in response_data:
            response_data["_user_rating"] = {}
        
        rating_data = {
            "rating": request.rating,
            "rated_at": datetime.now().isoformat(),
        }
        
        if request.strategy:
            rating_data["strategy"] = request.strategy
        
        if request.feedback:
            rating_data["feedback"] = request.feedback
        
        # ì „ëµë³„ë¡œ í‰ê°€ ì €ì¥ (ë‹¤ì¤‘ ì „ëµ ì§€ì›)
        if request.strategy:
            response_data["_user_rating"][request.strategy] = rating_data
        else:
            response_data["_user_rating"]["default"] = rating_data
        
        # íŒŒì¼ ì—…ë°ì´íŠ¸
        with open(response_path, 'w', encoding='utf-8') as f:
            json.dump(response_data, f, ensure_ascii=False, indent=2)
        
        logger.info(
            f"[í‰ê°€ ì €ì¥] íŒŒì¼={request.response_file}, "
            f"ì „ëµ={request.strategy or 'default'}, ë³„ì ={request.rating}"
        )
        
        return RateResponseResponse(
            success=True,
            message="í‰ê°€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤",
            response_file=request.response_file,
            rating=request.rating
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í‰ê°€ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"í‰ê°€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )
